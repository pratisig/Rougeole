# ============================================================
# APP COMPLET ‚Äì SURVEILLANCE & PR√âDICTION ROUGEOLE (Multi-pays)
# Version am√©lior√©e selon sp√©cifications
# PARTIE 1/5 - IMPORTS, CONFIG ET CHARGEMENT DONN√âES
# ============================================================

import streamlit as st
import pandas as pd
import numpy as np
import geopandas as gpd
from datetime import datetime, timedelta
import requests
from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor
from sklearn.linear_model import Ridge, Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split, cross_val_score
import ee
import json
import folium
from folium.plugins import HeatMap, MarkerCluster
from streamlit_folium import st_folium
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from io import BytesIO
import zipfile
import tempfile
import os
from shapely.geometry import shape
import warnings
warnings.filterwarnings('ignore')

# CONFIG STREAMLIT
st.set_page_config(
    page_title="Surveillance Rougeole Multi-pays",
    layout="wide",
    page_icon="ü¶†",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
.metric-card{background-color:#f0f2f6;padding:15px;border-radius:10px;box-shadow:2px 2px 5px rgba(0,0,0,0.1)}
.high-risk{background-color:#ffebee;color:#c62828;font-weight:bold;padding:5px;border-radius:3px}
.medium-risk{background-color:#fff3e0;color:#ef6c00;padding:5px;border-radius:3px}
.low-risk{background-color:#e8f5e9;color:#2e7d32;padding:5px;border-radius:3px}
.stButton>button{width:100%}
h1{color:#d32f2f}
.info-box{background-color:#e3f2fd;padding:10px;border-left:4px solid #2196f3;margin:10px 0}
.model-hint{background-color:#fff9c4;padding:8px;border-radius:5px;font-size:0.9em;margin:5px 0}
</style>
""", unsafe_allow_html=True)

st.title("ü¶† Dashboard de Surveillance et Pr√©diction - Rougeole")
st.markdown("### Analyse √©pid√©miologique et mod√©lisation pr√©dictive par semaines √©pid√©miologiques")

PAYS_ISO3_MAP = {
    "Niger": "ner",
    "Burkina Faso": "bfa",
    "Mali": "mli",
    "Mauritanie": "mrt"
}

# ============================================================
# INITIALISATION GOOGLE EARTH ENGINE
# ============================================================

@st.cache_resource
def init_gee():
    try:
        key_dict = json.loads(st.secrets["GEE_SERVICE_ACCOUNT"])
        credentials = ee.ServiceAccountCredentials(
            key_dict["client_email"],
            key_data=json.dumps(key_dict)
        )
        ee.Initialize(credentials)
        return True
    except:
        try:
            ee.Initialize()
            return True
        except:
            return False

gee_ok = init_gee()
if gee_ok:
    st.sidebar.success("‚úì GEE connect√©")

# ============================================================
# SIDEBAR - CONFIGURATION
# ============================================================

st.sidebar.header("üìÇ Configuration de l'Analyse")

# Session state pour le cache
if 'pays_precedent' not in st.session_state:
    st.session_state.pays_precedent = None
if 'sa_gdf_cache' not in st.session_state:
    st.session_state.sa_gdf_cache = None

# MODE D√âMO
st.sidebar.subheader("üéØ Mode d'utilisation")
mode_demo = st.sidebar.radio(
    "Choisissez votre mode",
    ["üìä Donn√©es r√©elles", "üß™ Mode d√©mo (donn√©es simul√©es)"],
    help="Mode d√©mo : g√©n√®re automatiquement des donn√©es fictives pour tester l'application"
)

# AIRES DE SANT√â
st.sidebar.subheader("üó∫Ô∏è Aires de Sant√©")
option_aire = st.sidebar.radio(
    "Source des donn√©es g√©ographiques",
    ["Fichier local (ao_hlthArea.zip)", "Upload personnalis√©"],
    key='option_aire'
)

pays_selectionne = None
iso3_pays = None

if option_aire == "Fichier local (ao_hlthArea.zip)":
    pays_selectionne = st.sidebar.selectbox(
        "üåç S√©lectionner le pays",
        list(PAYS_ISO3_MAP.keys()),
        key='pays_select'
    )
    iso3_pays = PAYS_ISO3_MAP[pays_selectionne]
    
    pays_change = (st.session_state.pays_precedent != pays_selectionne)
    if pays_change:
        st.session_state.pays_precedent = pays_selectionne
        st.session_state.sa_gdf_cache = None
        st.rerun()

upload_file = None
if option_aire == "Upload personnalis√©":
    upload_file = st.sidebar.file_uploader(
        "Charger un fichier g√©ographique",
        type=["shp", "geojson", "zip"],
        help="Format: Shapefile ou GeoJSON avec colonnes 'iso3' et 'health_area'"
    )

# DONN√âES √âPID√âMIOLOGIQUES
st.sidebar.subheader("üìä Donn√©es √âpid√©miologiques")

if mode_demo == "üß™ Mode d√©mo (donn√©es simul√©es)":
    option_linelist = "Donn√©es fictives (test)"
    linelist_file = None
    vaccination_file = None
    st.sidebar.info("üìä Mode d√©mo activ√© - Donn√©es simul√©es")
else:
    linelist_file = st.sidebar.file_uploader(
        "üìã Linelists rougeole (CSV)",
        type=["csv"],
        help="Format: health_area, Semaine_Epi, Cas_Total OU Date_Debut_Eruption, Aire_Sante..."
    )
    
    vaccination_file = st.sidebar.file_uploader(
        "üíâ Couverture vaccinale (CSV - optionnel)",
        type=["csv"],
        help="Format: health_area, Taux_Vaccination (en %)"
    )

# P√âRIODE D'ANALYSE
st.sidebar.subheader("üìÖ P√©riode d'Analyse")
col1, col2 = st.sidebar.columns(2)
with col1:
    start_date = st.date_input(
        "Date d√©but",
        value=datetime(2024, 1, 1),
        key='start_date'
    )
with col2:
    end_date = st.date_input(
        "Date fin",
        value=datetime.today(),
        key='end_date'
    )

# PARAM√àTRES DE PR√âDICTION
st.sidebar.subheader("üîÆ Param√®tres de Pr√©diction")
pred_mois = st.sidebar.slider(
    "P√©riode de pr√©diction (mois)",
    min_value=1,
    max_value=12,
    value=3,
    help="Nombre de mois √† pr√©dire apr√®s la derni√®re semaine de donn√©es"
)
n_weeks_pred = pred_mois * 4

st.sidebar.info(f"üìÜ Pr√©diction sur **{n_weeks_pred} semaines √©pid√©miologiques** (~{pred_mois} mois)")

# CHOIX DU MOD√àLE
st.sidebar.subheader("ü§ñ Mod√®le de Pr√©diction")

modele_choisi = st.sidebar.selectbox(
    "Choisissez votre algorithme",
    [
        "GradientBoosting (Recommand√©)",
        "RandomForest",
        "Ridge Regression",
        "Lasso Regression",
        "Decision Tree"
    ],
    help="S√©lectionnez l'algorithme de machine learning pour la pr√©diction"
)

# Hints pour chaque mod√®le
model_hints = {
    "GradientBoosting (Recommand√©)": "üéØ **Gradient Boosting** : Tr√®s performant pour les s√©ries temporelles. Combine plusieurs mod√®les faibles pour cr√©er un mod√®le fort. Excellent pour capturer les relations non-lin√©aires. Recommand√© pour la surveillance √©pid√©miologique.",
    "RandomForest": "üå≥ **Random Forest** : Ensemble d'arbres de d√©cision. Robuste aux valeurs aberrantes et aux donn√©es manquantes. Bon pour les interactions complexes entre variables.",
    "Ridge Regression": "üìä **Ridge Regression** : R√©gression lin√©aire avec r√©gularisation L2. Simple et rapide. Id√©al pour relations lin√©aires. Moins performant sur donn√©es non-lin√©aires.",
    "Lasso Regression": "üéØ **Lasso Regression** : R√©gularisation L1 avec s√©lection automatique des variables. Utile quand beaucoup de variables peu importantes. Simplifie le mod√®le.",
    "Decision Tree": "üå≤ **Decision Tree** : Arbre de d√©cision unique. Simple √† interpr√©ter mais risque de sur-apprentissage. Moins robuste que les m√©thodes d'ensemble."
}

st.sidebar.markdown(f'<div class="model-hint">{model_hints[modele_choisi]}</div>', unsafe_allow_html=True)

# SEUILS D'ALERTE
st.sidebar.subheader("‚öôÔ∏è Seuils d'Alerte")
with st.sidebar.expander("Configurer les seuils", expanded=False):
    seuil_baisse = st.slider(
        "Seuil de baisse significative (%)",
        min_value=10,
        max_value=90,
        value=75,
        step=5,
        help="Afficher les aires avec baisse ‚â• X% par rapport √† la moyenne"
    )
    seuil_hausse = st.slider(
        "Seuil de hausse significative (%)",
        min_value=10,
        max_value=200,
        value=50,
        step=10,
        help="Afficher les aires avec hausse ‚â• X% par rapport √† la moyenne"
    )
    seuil_alerte_epidemique = st.number_input(
        "Seuil d'alerte √©pid√©mique (cas/semaine)",
        min_value=1,
        max_value=100,
        value=5,
        help="Nombre de cas par semaine d√©clenchant une alerte"
    )

# ============================================================
# FONCTIONS DE CHARGEMENT DES DONN√âES G√âOGRAPHIQUES
# ============================================================

@st.cache_data
def load_health_areas_from_zip(zip_path, iso3_filter):
    try:
        with tempfile.TemporaryDirectory() as tmpdir:
            with zipfile.ZipFile(zip_path, 'r') as z:
                z.extractall(tmpdir)
            
            shp_files = [f for f in os.listdir(tmpdir) if f.endswith('.shp')]
            if not shp_files:
                raise ValueError("Aucun fichier .shp trouv√© dans le ZIP")
            
            shp_path = os.path.join(tmpdir, shp_files[0])
            gdf_full = gpd.read_file(shp_path)
            
            # Trouver la colonne ISO3
            iso3_col = None
            for col in ['iso3', 'ISO3', 'iso_code', 'ISO_CODE', 'country_iso', 'COUNTRY_ISO']:
                if col in gdf_full.columns:
                    iso3_col = col
                    break
            
            if iso3_col is None:
                st.warning(f"‚ö†Ô∏è Colonne ISO3 non trouv√©e. Colonnes: {list(gdf_full.columns)}")
                return gpd.GeoDataFrame()
            
            gdf = gdf_full[gdf_full[iso3_col] == iso3_filter].copy()
            
            if gdf.empty:
                st.warning(f"‚ö†Ô∏è Aucune aire de sant√© pour {iso3_filter}")
                return gpd.GeoDataFrame()
            
            # Trouver la colonne nom
            name_col = None
            for col in ['health_area', 'HEALTH_AREA', 'name_fr', 'name', 'NAME', 'nom', 'NOM', 'aire_sante']:
                if col in gdf.columns:
                    name_col = col
                    break
            
            if name_col:
                gdf['health_area'] = gdf[name_col]
            else:
                gdf['health_area'] = [f"Aire_{i+1}" for i in range(len(gdf))]
            
            gdf = gdf[gdf.geometry.is_valid]
            
            if gdf.crs is None:
                gdf.set_crs("EPSG:4326", inplace=True)
            elif gdf.crs.to_epsg() != 4326:
                gdf = gdf.to_crs("EPSG:4326")
            
            return gdf
            
    except Exception as e:
        st.error(f"‚ùå Erreur ZIP: {e}")
        return gpd.GeoDataFrame()

def load_shapefile_from_upload(upload_file):
    try:
        if upload_file.name.endswith('.zip'):
            with tempfile.TemporaryDirectory() as tmpdir:
                zip_path = os.path.join(tmpdir, 'upload.zip')
                with open(zip_path, 'wb') as f:
                    f.write(upload_file.getvalue())
                
                with zipfile.ZipFile(zip_path, 'r') as z:
                    z.extractall(tmpdir)
                    shp_files = [f for f in os.listdir(tmpdir) if f.endswith('.shp')]
                    if shp_files:
                        gdf = gpd.read_file(os.path.join(tmpdir, shp_files[0]))
                    else:
                        raise ValueError("Aucun .shp trouv√©")
        else:
            gdf = gpd.read_file(upload_file)
        
        if "health_area" not in gdf.columns:
            for col in ["health_area", "HEALTH_AREA", "name_fr", "name", "NAME", "nom", "NOM"]:
                if col in gdf.columns:
                    gdf["health_area"] = gdf[col]
                    break
            else:
                gdf["health_area"] = [f"Aire_{i}" for i in range(len(gdf))]
        
        gdf = gdf[gdf.geometry.is_valid]
        
        if gdf.crs is None:
            gdf.set_crs("EPSG:4326", inplace=True)
        elif gdf.crs.to_epsg() != 4326:
            gdf = gdf.to_crs("EPSG:4326")
        
        return gdf
        
    except Exception as e:
        st.error(f"‚ùå Erreur lecture: {e}")
        return gpd.GeoDataFrame()

# ============================================================
# PARTIE 2/5 - CHARGEMENT AIRES DE SANT√â ET DONN√âES DE CAS
# ============================================================

# CHARGEMENT DES AIRES DE SANT√â
if st.session_state.sa_gdf_cache is not None and option_aire == "Fichier local (ao_hlthArea.zip)":
    sa_gdf = st.session_state.sa_gdf_cache
    st.sidebar.success(f"‚úì {len(sa_gdf)} aires charg√©es (cache)")
else:
    with st.spinner(f"üîÑ Chargement des aires de sant√©..."):
        if option_aire == "Fichier local (ao_hlthArea.zip)":
            zip_path = os.path.join("data", "ao_hlthArea.zip")
            if not os.path.exists(zip_path):
                st.error(f"‚ùå Fichier non trouv√©: {zip_path}")
                st.info("üìÅ Placez 'ao_hlthArea.zip' dans le dossier 'data/'")
                st.stop()
            
            sa_gdf = load_health_areas_from_zip(zip_path, iso3_pays)
            
            if sa_gdf.empty:
                st.error(f"‚ùå Impossible de charger {pays_selectionne} ({iso3_pays})")
                st.stop()
            else:
                st.sidebar.success(f"‚úì {len(sa_gdf)} aires charg√©es ({iso3_pays})")
                st.session_state.sa_gdf_cache = sa_gdf
                
        elif option_aire == "Upload personnalis√©":
            if upload_file is None:
                st.warning("‚ö†Ô∏è Veuillez uploader un fichier")
                st.stop()
            else:
                sa_gdf = load_shapefile_from_upload(upload_file)
                if sa_gdf.empty:
                    st.error("‚ùå Fichier invalide")
                    st.stop()
                else:
                    st.sidebar.success(f"‚úì {len(sa_gdf)} aires charg√©es")
                    st.session_state.sa_gdf_cache = sa_gdf

if sa_gdf.empty or sa_gdf is None:
    st.error("‚ùå Aucune aire charg√©e")
    st.stop()

# ============================================================
# G√âN√âRATION DE DONN√âES FICTIVES
# ============================================================

@st.cache_data
def generate_dummy_linelists(_sa_gdf, n=500, start=None, end=None):
    """G√©n√®re des donn√©es de cas fictives pour le mode d√©mo"""
    np.random.seed(42)
    
    if start is None:
        start = datetime(2024, 1, 1)
    if end is None:
        end = datetime.today()
    
    delta_days = (end - start).days
    dates = pd.to_datetime(start) + pd.to_timedelta(
        np.random.exponential(scale=delta_days/3, size=n).clip(0, delta_days).astype(int),
        unit="D"
    )
    
    df = pd.DataFrame({
        "ID_Cas": range(1, n+1),
        "Date_Debut_Eruption": dates,
        "Date_Notification": dates + pd.to_timedelta(np.random.poisson(3, n), unit="D"),
        "Aire_Sante": np.random.choice(_sa_gdf["health_area"].unique(), n),
        "Age_Mois": np.random.gamma(shape=2, scale=30, size=n).clip(6, 180).astype(int),
        "Statut_Vaccinal": np.random.choice(["Oui", "Non"], n, p=[0.55, 0.45]),
        "Sexe": np.random.choice(["M", "F"], n),
        "Issue": np.random.choice(["Gu√©ri", "D√©c√©d√©", "Inconnu"], n, p=[0.92, 0.03, 0.05])
    })
    
    return df

@st.cache_data
def generate_dummy_vaccination(_sa_gdf):
    """G√©n√®re des donn√©es de couverture vaccinale fictives"""
    np.random.seed(42)
    
    return pd.DataFrame({
        "health_area": _sa_gdf["health_area"],
        "Taux_Vaccination": np.random.beta(a=8, b=2, size=len(_sa_gdf)) * 100  # Biais√© vers 80%
    })

# ============================================================
# CHARGEMENT DES DONN√âES DE CAS
# ============================================================

with st.spinner("üì• Chargement donn√©es de cas..."):
    if mode_demo == "üß™ Mode d√©mo (donn√©es simul√©es)":
        df = generate_dummy_linelists(sa_gdf, start=start_date, end=end_date)
        vaccination_df = generate_dummy_vaccination(sa_gdf)
        st.sidebar.info(f"üìä {len(df)} cas simul√©s g√©n√©r√©s")
        
    else:
        if linelist_file is None:
            st.error("‚ùå Veuillez uploader un fichier CSV de lineliste")
            st.stop()
            
        try:
            df_raw = pd.read_csv(linelist_file)
            
            # V√©rifier si format agr√©g√© ou d√©taill√©
            if "Semaine_Epi" in df_raw.columns and "Cas_Total" in df_raw.columns:
                # Format agr√©g√© - expansion n√©cessaire
                expanded_rows = []
                for _, row in df_raw.iterrows():
                    aire = row.get("health_area") or row.get("Aire_Sante") or row.get("name_fr")
                    semaine = int(row["Semaine_Epi"])
                    cas_total = int(row["Cas_Total"])
                    annee = row.get("Annee", 2024)
                    
                    base_date = datetime.strptime(f"{annee}-W{semaine:02d}-1", "%Y-W%W-%w")
                    
                    for i in range(cas_total):
                        expanded_rows.append({
                            "ID_Cas": len(expanded_rows) + 1,
                            "Date_Debut_Eruption": base_date + timedelta(days=np.random.randint(0, 7)),
                            "Date_Notification": base_date + timedelta(days=np.random.randint(0, 10)),
                            "Aire_Sante": aire,
                            "Age_Mois": 0,
                            "Statut_Vaccinal": "Inconnu",
                            "Sexe": "Inconnu",
                            "Issue": "Inconnu"
                        })
                
                df = pd.DataFrame(expanded_rows)
                
            elif "Date_Debut_Eruption" in df_raw.columns:
                # Format d√©taill√©
                df = df_raw.copy()
                
                for col in ["Date_Debut_Eruption", "Date_Notification"]:
                    if col in df.columns:
                        df[col] = pd.to_datetime(df[col], errors='coerce')
            else:
                st.error("‚ùå Format CSV non reconnu. Colonnes requises: 'Date_Debut_Eruption' ou 'Semaine_Epi'+'Cas_Total'")
                st.stop()
            
            st.sidebar.success(f"‚úì {len(df)} cas charg√©s")
            
        except Exception as e:
            st.error(f"‚ùå Erreur CSV: {e}")
            st.stop()
        
        # Charger donn√©es de vaccination si fournies
        if vaccination_file is not None:
            try:
                vaccination_df = pd.read_csv(vaccination_file)
                st.sidebar.success(f"‚úì Couverture vaccinale charg√©e ({len(vaccination_df)} aires)")
            except Exception as e:
                st.sidebar.warning(f"‚ö†Ô∏è Erreur vaccination CSV: {e}")
                vaccination_df = None
        else:
            # V√©rifier si Statut_Vaccinal dans linelist
            if "Statut_Vaccinal" in df.columns:
                # Calculer le taux par aire
                vacc_by_area = df.groupby("Aire_Sante").agg({
                    "Statut_Vaccinal": lambda x: ((x == "Oui").sum() / len(x) * 100) if len(x) > 0 else 0
                }).reset_index()
                vacc_by_area.columns = ["health_area", "Taux_Vaccination"]
                vaccination_df = vacc_by_area
                st.sidebar.info("‚ÑπÔ∏è Taux vaccination extrait de la linelist")
            else:
                vaccination_df = None
                st.sidebar.info("‚ÑπÔ∏è Pas de donn√©es de vaccination")

# Filtrer par p√©riode
df = df[
    (df["Date_Debut_Eruption"] >= pd.to_datetime(start_date)) &
    (df["Date_Debut_Eruption"] <= pd.to_datetime(end_date))
].copy()

if len(df) == 0:
    st.warning("‚ö†Ô∏è Aucun cas dans la p√©riode")
    st.stop()

# Calculer semaine √©pid√©miologique
def calculer_semaine_epidemio(date):
    return date.isocalendar()[1]

df['Semaine_Epi'] = df['Date_Debut_Eruption'].apply(calculer_semaine_epidemio)
df['Annee'] = df['Date_Debut_Eruption'].dt.year
df['Semaine_Annee'] = df['Annee'].astype(str) + '-S' + df['Semaine_Epi'].astype(str).str.zfill(2)

derniere_semaine_epi = df['Semaine_Epi'].max()
derniere_annee = df['Annee'].max()

st.sidebar.info(f"üìÖ Derni√®re semaine: **S{derniere_semaine_epi}** ({derniere_annee})")

# ============================================================
# PARTIE 3/5 - ENRICHISSEMENT AVEC DONN√âES EXTERNES
# WorldPop, NASA POWER, GHSL
# ============================================================

# ============================================================
# WORLDPOP - DONN√âES D√âMOGRAPHIQUES (VERSION CORRIG√âE)
# ============================================================

@st.cache_data
def worldpop_children_stats(_sa_gdf, use_gee):
    """
    Extraction des statistiques WorldPop avec la logique correcte
    Retourne: gar√ßons, filles, population totale, enfants
    """
    if not use_gee:
        st.sidebar.warning("‚ö†Ô∏è WorldPop: GEE indisponible")
        return pd.DataFrame({
            "health_area": _sa_gdf["health_area"],
            "Pop_Totale": [np.nan] * len(_sa_gdf),
            "Pop_Garcons": [np.nan] * len(_sa_gdf),
            "Pop_Filles": [np.nan] * len(_sa_gdf),
            "Pop_Enfants": [np.nan] * len(_sa_gdf)
        })
    
    try:
        # Barre de progression
        progress_bar = st.sidebar.progress(0)
        status_text = st.sidebar.empty()
        
        # Chargement et mosa√Øque WorldPop
        status_text.text("üì• Chargement WorldPop...")
        dataset = ee.ImageCollection("WorldPop/GP/100m/pop_age_sex")
        pop_img = dataset.mosaic()
        
        # S√©lection des bandes
        male_bands = ["M_0", "M_1", "M_5", "M_10"]
        female_bands = ["F_0", "F_1", "F_5", "F_10"]
        
        selected_males = pop_img.select(male_bands)
        selected_females = pop_img.select(female_bands)
        total_pop = pop_img.select(['population'])
        
        # Calcul de la bande enfants (somme M + F)
        enfants = selected_males.add(selected_females).reduce(ee.Reducer.sum()).rename('enfants')
        
        # Assemblage final
        final_mosaic = selected_males.addBands(selected_females).addBands(total_pop).addBands(enfants)
        
        # Cr√©ation des features GEE
        status_text.text("üó∫Ô∏è Conversion g√©om√©tries...")
        features = []
        for idx, row in _sa_gdf.iterrows():
            geom = row['geometry']
            props = {"health_area": row["health_area"]}
            
            if geom.geom_type == 'Polygon':
                coords = [[[x, y] for x, y in geom.exterior.coords]]
                ee_geom = ee.Geometry.Polygon(coords)
            elif geom.geom_type == 'MultiPolygon':
                coords = []
                for poly in geom.geoms:
                    coords.append([[[x, y] for x, y in poly.exterior.coords]])
                ee_geom = ee.Geometry.MultiPolygon(coords)
            else:
                continue
            
            features.append(ee.Feature(ee_geom, props))
        
        fc = ee.FeatureCollection(features)
        
        # Statistiques zonales
        status_text.text("üî¢ Calcul statistiques zonales...")
        stats = final_mosaic.reduceRegions(
            collection=fc,
            reducer=ee.Reducer.sum(),
            scale=100
        )
        
        # Extraction des r√©sultats
        status_text.text("üìä Extraction r√©sultats...")
        stats_info = stats.getInfo()
        
        data_list = []
        total_aires = len(stats_info['features'])
        
        for i, feat in enumerate(stats_info['features']):
            props = feat['properties']
            
            # Somme des gar√ßons (M_0 + M_1 + M_5 + M_10)
            garcons = sum([props.get(band, 0) for band in male_bands])
            
            # Somme des filles (F_0 + F_1 + F_5 + F_10)
            filles = sum([props.get(band, 0) for band in female_bands])
            
            # Population totale
            pop_totale = props.get("population", 0)
            
            # Enfants (gar√ßons + filles)
            enfants_total = props.get("enfants", garcons + filles)
            
            data_list.append({
                "health_area": props.get("health_area", ""),
                "Pop_Totale": int(pop_totale) if pop_totale > 0 else np.nan,
                "Pop_Garcons": int(garcons),
                "Pop_Filles": int(filles),
                "Pop_Enfants": int(enfants_total)
            })
            
            # Mise √† jour progression
            progress_bar.progress((i + 1) / total_aires)
        
        progress_bar.empty()
        status_text.text("‚úÖ WorldPop termin√©")
        
        return pd.DataFrame(data_list)
        
    except Exception as e:
        st.sidebar.error(f"‚ùå WorldPop: {str(e)}")
        progress_bar.empty()
        status_text.empty()
        return pd.DataFrame({
            "health_area": _sa_gdf["health_area"],
            "Pop_Totale": [np.nan] * len(_sa_gdf),
            "Pop_Garcons": [np.nan] * len(_sa_gdf),
            "Pop_Filles": [np.nan] * len(_sa_gdf),
            "Pop_Enfants": [np.nan] * len(_sa_gdf)
        })

# ============================================================
# GHSL - CLASSIFICATION URBAINE
# ============================================================

@st.cache_data
def urban_classification(_sa_gdf, use_gee):
    """Classification urbaine via GHSL"""
    if not use_gee:
        st.sidebar.warning("‚ö†Ô∏è GHSL: GEE indisponible")
        return pd.DataFrame({
            "health_area": _sa_gdf["health_area"],
            "Urbanisation": [np.nan] * len(_sa_gdf)
        })
    
    try:
        progress_bar = st.sidebar.progress(0)
        status_text = st.sidebar.empty()
        status_text.text("üèôÔ∏è Classification urbaine...")
        
        features = []
        for idx, row in _sa_gdf.iterrows():
            geom = row['geometry']
            props = {"health_area": row["health_area"]}
            
            if geom.geom_type == 'Polygon':
                coords = [[[x, y] for x, y in geom.exterior.coords]]
                ee_geom = ee.Geometry.Polygon(coords)
            elif geom.geom_type == 'MultiPolygon':
                coords = []
                for poly in geom.geoms:
                    coords.append([[[x, y] for x, y in poly.exterior.coords]])
                ee_geom = ee.Geometry.MultiPolygon(coords)
            else:
                continue
            
            features.append(ee.Feature(ee_geom, props))
        
        fc = ee.FeatureCollection(features)
        smod = ee.Image("JRC/GHSL/P2023A/GHS_SMOD/2020")
        
        def classify(feature):
            stats = smod.reduceRegion(
                ee.Reducer.mode(),
                feature.geometry(),
                scale=1000,
                maxPixels=1e9
            )
            smod_value = ee.Number(stats.get("smod_code")).toInt()
            urbanisation = ee.Algorithms.If(
                smod_value.gte(30),
                "Urbain",
                ee.Algorithms.If(smod_value.eq(23), "Semi-urbain", "Rural")
            )
            return feature.set({"Urbanisation": urbanisation})
        
        urban_fc = fc.map(classify)
        urban_info = urban_fc.getInfo()
        
        data_list = []
        total_aires = len(urban_info['features'])
        
        for i, feat in enumerate(urban_info['features']):
            props = feat['properties']
            data_list.append({
                "health_area": props.get("health_area", ""),
                "Urbanisation": props.get("Urbanisation", "Rural")
            })
            progress_bar.progress((i + 1) / total_aires)
        
        progress_bar.empty()
        status_text.text("‚úÖ GHSL termin√©")
        
        return pd.DataFrame(data_list)
        
    except Exception as e:
        st.sidebar.error(f"‚ùå GHSL: {str(e)}")
        progress_bar.empty()
        status_text.empty()
        return pd.DataFrame({
            "health_area": _sa_gdf["health_area"],
            "Urbanisation": [np.nan] * len(_sa_gdf)
        })

# ============================================================
# NASA POWER - DONN√âES CLIMATIQUES
# ============================================================

@st.cache_data(ttl=86400)
def fetch_climate_nasa_power(_sa_gdf, start_date, end_date):
    """R√©cup√©ration donn√©es climatiques NASA POWER"""
    progress_bar = st.sidebar.progress(0)
    status_text = st.sidebar.empty()
    
    data_list = []
    total_aires = len(_sa_gdf)
    
    for idx, row in _sa_gdf.iterrows():
        status_text.text(f"üå°Ô∏è Climat {idx+1}/{total_aires}...")
        
        lat, lon = row.geometry.centroid.y, row.geometry.centroid.x
        
        url = "https://power.larc.nasa.gov/api/temporal/daily/point"
        params = {
            "parameters": "T2M,PRECTOTCORR,RH2M",
            "community": "AG",
            "longitude": lon,
            "latitude": lat,
            "start": start_date.strftime("%Y%m%d"),
            "end": end_date.strftime("%Y%m%d"),
            "format": "JSON"
        }
        
        try:
            r = requests.get(url, params=params, timeout=30)
            j = r.json()
            
            if "properties" in j and "parameter" in j["properties"]:
                p = j["properties"]["parameter"]
                
                temp_values = list(p.get("T2M", {}).values())
                rh_values = list(p.get("RH2M", {}).values())
                
                temp_mean = np.nanmean(temp_values) if temp_values else np.nan
                rh_mean = np.nanmean(rh_values) if rh_values else np.nan
                
                # Indicateur saison s√®che (humidit√© r√©duite)
                saison_seche_hum = rh_mean * 0.7 if not np.isnan(rh_mean) else np.nan
                
                data_list.append({
                    "health_area": row["health_area"],
                    "Temperature_Moy": temp_mean,
                    "Humidite_Moy": rh_mean,
                    "Saison_Seche_Humidite": saison_seche_hum
                })
            else:
                data_list.append({
                    "health_area": row["health_area"],
                    "Temperature_Moy": np.nan,
                    "Humidite_Moy": np.nan,
                    "Saison_Seche_Humidite": np.nan
                })
        except:
            data_list.append({
                "health_area": row["health_area"],
                "Temperature_Moy": np.nan,
                "Humidite_Moy": np.nan,
                "Saison_Seche_Humidite": np.nan
            })
        
        progress_bar.progress((idx + 1) / total_aires)
    
    progress_bar.empty()
    status_text.text("‚úÖ Climat termin√©")
    
    return pd.DataFrame(data_list)

# ============================================================
# ENRICHISSEMENT DU GEODATAFRAME
# ============================================================

with st.spinner("üîÑ Enrichissement des donn√©es..."):
    
    # WorldPop
    pop_df = worldpop_children_stats(sa_gdf, gee_ok)
    
    # GHSL
    urban_df = urban_classification(sa_gdf, gee_ok)
    
    # NASA POWER
    climate_df = fetch_climate_nasa_power(sa_gdf, start_date, end_date)

# Fusion des donn√©es
sa_gdf_enrichi = sa_gdf.copy()
sa_gdf_enrichi = sa_gdf_enrichi.merge(pop_df, on="health_area", how="left")
sa_gdf_enrichi = sa_gdf_enrichi.merge(urban_df, on="health_area", how="left")
sa_gdf_enrichi = sa_gdf_enrichi.merge(climate_df, on="health_area", how="left")

# Ajout des donn√©es de vaccination si disponibles
if vaccination_df is not None:
    sa_gdf_enrichi = sa_gdf_enrichi.merge(vaccination_df, on="health_area", how="left")
else:
    sa_gdf_enrichi["Taux_Vaccination"] = np.nan

# Calcul superficie et densit√©s
sa_gdf_enrichi["Superficie_km2"] = sa_gdf_enrichi.geometry.area / 1e6

# Densit√© population totale (correcte maintenant)
sa_gdf_enrichi["Densite_Pop"] = (
    sa_gdf_enrichi["Pop_Totale"] / sa_gdf_enrichi["Superficie_km2"].replace(0, np.nan)
)

# Densit√© enfants
sa_gdf_enrichi["Densite_Enfants"] = (
    sa_gdf_enrichi["Pop_Enfants"] / sa_gdf_enrichi["Superficie_km2"].replace(0, np.nan)
)

# Nettoyage des valeurs infinies
sa_gdf_enrichi = sa_gdf_enrichi.replace([np.inf, -np.inf], np.nan)

st.sidebar.success("‚úì Enrichissement termin√©")

# R√©sum√© des donn√©es disponibles
st.sidebar.markdown("---")
st.sidebar.subheader("üìã Donn√©es disponibles")

donnees_dispo = {
    "Population": not sa_gdf_enrichi["Pop_Totale"].isna().all(),
    "Urbanisation": not sa_gdf_enrichi["Urbanisation"].isna().all(),
    "Climat": not sa_gdf_enrichi["Humidite_Moy"].isna().all(),
    "Vaccination": not sa_gdf_enrichi["Taux_Vaccination"].isna().all()
}

for nom, dispo in donnees_dispo.items():
    icone = "‚úÖ" if dispo else "‚ùå"
    st.sidebar.text(f"{icone} {nom}")

# ============================================================
# PARTIE 4/5 - KPIS, CARTE ET ANALYSES (VERSION AM√âLIOR√âE)
# ============================================================

# ============================================================
# KPIS
# ============================================================

st.header("üìä Indicateurs Cl√©s de Performance")

col1, col2, col3, col4, col5 = st.columns(5)

with col1:
    st.metric("üìà Cas totaux", f"{len(df):,}")

with col2:
    taux_non_vac = (df["Statut_Vaccinal"] == "Non").mean() * 100
    delta_vac = taux_non_vac - 45
    st.metric("üíâ Non vaccin√©s", f"{taux_non_vac:.1f}%", delta=f"{delta_vac:+.1f}%")

with col3:
    age_median = df["Age_Mois"].median()
    st.metric("üë∂ √Çge m√©dian", f"{int(age_median)} mois")

with col4:
    if "Issue" in df.columns:
        taux_deces = (df["Issue"] == "D√©c√©d√©").mean() * 100
        st.metric("‚ò†Ô∏è L√©talit√©", f"{taux_deces:.2f}%")
    else:
        st.metric("‚ò†Ô∏è L√©talit√©", "N/A")

with col5:
    n_aires_touchees = df["Aire_Sante"].nunique()
    pct_aires = (n_aires_touchees / len(sa_gdf)) * 100
    st.metric("üó∫Ô∏è Aires touch√©es", f"{n_aires_touchees}/{len(sa_gdf)}", delta=f"{pct_aires:.0f}%")

# Agr√©gation par aire
cases_by_area = df.groupby("Aire_Sante").agg({
    "ID_Cas": "count",
    "Statut_Vaccinal": lambda x: (x == "Non").mean() * 100,
    "Age_Mois": "mean"
}).reset_index()

cases_by_area.columns = ["Aire_Sante", "Cas_Observes", "Taux_Non_Vaccines", "Age_Moyen"]

sa_gdf_with_cases = sa_gdf_enrichi.merge(
    cases_by_area,
    left_on="health_area",
    right_on="Aire_Sante",
    how="left"
)

sa_gdf_with_cases["Cas_Observes"] = sa_gdf_with_cases["Cas_Observes"].fillna(0)
sa_gdf_with_cases["Taux_Non_Vaccines"] = sa_gdf_with_cases["Taux_Non_Vaccines"].fillna(0)

# Taux d'attaque pour 10,000 enfants
sa_gdf_with_cases["Taux_Attaque_10000"] = (
    sa_gdf_with_cases["Cas_Observes"] / sa_gdf_with_cases["Pop_Enfants"].replace(0, np.nan) * 10000
).replace([np.inf, -np.inf], np.nan)

# ============================================================
# CARTE AM√âLIOR√âE (contours fins, √©tiquettes sans fond)
# ============================================================

st.header("üó∫Ô∏è Cartographie de la Situation Actuelle")

center_lat = sa_gdf_with_cases.geometry.centroid.y.mean()
center_lon = sa_gdf_with_cases.geometry.centroid.x.mean()

m = folium.Map(
    location=[center_lat, center_lon],
    zoom_start=6,
    tiles="CartoDB positron",
    control_scale=True
)

# Colormap
import branca.colormap as cm
max_cases = sa_gdf_with_cases["Cas_Observes"].max()
if max_cases > 0:
    colormap = cm.LinearColormap(
        colors=['#e8f5e9', '#81c784', '#ffeb3b', '#ff9800', '#f44336', '#b71c1c'],
        vmin=0,
        vmax=max_cases,
        caption="Nombre de cas observ√©s"
    )
    colormap.add_to(m)

# Ajout des polygones
for idx, row in sa_gdf_with_cases.iterrows():
    aire_name = row['health_area']
    cas_obs = int(row.get('Cas_Observes', 0))
    pop_enfants = row.get('Pop_Enfants', np.nan)
    taux_attaque = row.get('Taux_Attaque_10000', np.nan)
    urbanisation = row.get('Urbanisation', 'N/A')
    densite = row.get('Densite_Pop', np.nan)
    
    # Popup enrichi
    popup_html = f"""
    <div style="font-family: Arial; width: 350px;">
        <h3 style="margin-bottom: 10px; color: #1976d2; border-bottom: 2px solid #1976d2;">
            {aire_name}
        </h3>
        <div style="background-color: #f5f5f5; padding: 10px; margin: 10px 0; border-radius: 5px;">
            <h4 style="margin: 0; color: #d32f2f;">üìä Situation √âpid√©miologique</h4>
            <table style="width: 100%; margin-top: 5px;">
                <tr><td><b>Cas observ√©s:</b></td><td style="text-align: right;">
                    <b style="font-size: 18px; color: #d32f2f;">{cas_obs}</b>
                </td></tr>
                <tr><td>Population enfants:</td><td style="text-align: right;">
                    {f"{int(pop_enfants):,}" if not np.isnan(pop_enfants) else "N/A"}
                </td></tr>
                <tr><td>Taux d'attaque:</td><td style="text-align: right;">
                    {f"{taux_attaque:.1f}/10K" if not np.isnan(taux_attaque) else "N/A"}
                </td></tr>
                <tr><td>Type habitat:</td><td style="text-align: right;">
                    <b>{urbanisation if pd.notna(urbanisation) else "N/A"}</b>
                </td></tr>
                <tr><td>Densit√© pop:</td><td style="text-align: right;">
                    {f"{densite:.1f} hab/km¬≤" if not np.isnan(densite) else "N/A"}
                </td></tr>
            </table>
        </div>
    </div>
    """
    
    fill_color = colormap(row['Cas_Observes']) if max_cases > 0 else '#e0e0e0'
    
    # AM√âLIORATION: Contours plus fins
    if row['Cas_Observes'] >= seuil_alerte_epidemique:
        line_color = '#b71c1c'
        line_weight = 2  # R√©duit de 3 √† 2
    else:
        line_color = 'black'
        line_weight = 0.5  # R√©duit de 1 √† 0.5
        
    folium.GeoJson(
        row['geometry'],
        style_function=lambda x, color=fill_color, weight=line_weight, border=line_color: {
            'fillColor': color,
            'color': border,
            'weight': weight,
            'fillOpacity': 0.7
        },
        tooltip=folium.Tooltip(
            f"<b>{aire_name}</b><br>{cas_obs} cas",
            sticky=True
        ),
        popup=folium.Popup(popup_html, max_width=400)
    ).add_to(m)
    
    # AM√âLIORATION: √âtiquettes sans fond blanc fixe
    if cas_obs > 0:
        folium.Marker(
            location=[row.geometry.centroid.y, row.geometry.centroid.x],
            icon=folium.DivIcon(html=f"""
                <div style="
                    font-size: 9pt;
                    color: black;
                    weight: bold;
                    background-color: rgba(255, 255, 255, 0.85);
                    padding: 1px 4px;
                    border-radius: 3px;
                    white-space: nowrap;
                    border: 1px solid rgba(0, 0, 0, 0.2);
                    box-shadow: 0 1px 2px rgba(0,0,0,0.1);
                ">
                    {aire_name}
                </div>
            """)
        ).add_to(m)

# Heatmap
heat_data = [
    [row.geometry.centroid.y, row.geometry.centroid.x, row['Cas_Observes']]
    for idx, row in sa_gdf_with_cases.iterrows() if row['Cas_Observes'] > 0
]
if heat_data:
    HeatMap(
        heat_data,
        radius=20,
        blur=25,
        max_zoom=13,
        gradient={0.0: 'blue', 0.5: 'yellow', 1.0: 'red'}
    ).add_to(m)

# L√©gende
st_folium(m, width="100%", height=600)

# --- ANALYSES GRAPHIQUES ---
col_left, col_right = st.columns(2)

with col_left:
    st.subheader("üìà √âvolution temporelle (Saisonnalit√©)")
    # Agr√©gation hebdomadaire
    weekly_trend = df.groupby('Semaine_Annee').size().reset_index(name='Cas')
    fig_trend = px.line(weekly_trend, x='Semaine_Annee', y='Cas', markers=True)
    fig_trend.update_layout(xaxis_tickangle=-45)
    st.plotly_chart(fig_trend, use_container_width=True)

with col_right:
    st.subheader("üë∂ Distribution par √Çge et Sexe")
    fig_age = px.histogram(df, x="Age_Mois", color="Sexe", nbins=20, barmode="group")
    st.plotly_chart(fig_age, use_container_width=True)

# ============================================================
# PARTIE 5/5 - MOD√âLISATION PR√âDICTIVE (MACHINE LEARNING)
# ============================================================

st.divider()
st.header("üîÆ Mod√©lisation Pr√©dictive & Alertes")

if st.button("üöÄ Lancer la mod√©lisation pr√©dictive", type="primary"):
    with st.spinner("üß† Pr√©paration des variables et entra√Ænement du mod√®le..."):
        
        # 1. Pr√©paration des donn√©es hebdomadaires (Training Set)
        # On cr√©e une grille de toutes les aires x toutes les semaines
        all_aires = sa_gdf_enrichi["health_area"].unique()
        all_weeks = sorted(df["Semaine_Epi"].unique())
        
        index = pd.MultiIndex.from_product([all_aires, all_weeks], names=["Aire_Sante", "Semaine_Epi"])
        weekly_features = pd.DataFrame(index=index).reset_index()
        
        # Ajout des cas observ√©s
        cas_counts = df.groupby(["Aire_Sante", "Semaine_Epi"]).size().reset_index(name="Cas_Observes")
        weekly_features = weekly_features.merge(cas_counts, on=["Aire_Sante", "Semaine_Epi"], how="left").fillna(0)
        
        # Ajout des variables statiques par aire
        weekly_features = weekly_features.merge(
            sa_gdf_enrichi[[
                "health_area", "Pop_Enfants", "Urbanisation", "Taux_Vaccination",
                "Temperature_Moy", "Humidite_Moy", "Densite_Pop"
            ]],
            left_on="Aire_Sante", right_on="health_area", how="left"
        )
        
        # Encodage de l'urbanisation
        le_urb = LabelEncoder()
        weekly_features["Urban_Enc"] = le_urb.fit_transform(weekly_features["Urbanisation"].fillna("Rural"))
        
        # Ajout des lags (historique local)
        weekly_features = weekly_features.sort_values(["Aire_Sante", "Semaine_Epi"])
        for i in range(1, 5):
            weekly_features[f"Cas_Lag_{i}"] = weekly_features.groupby("Aire_Sante")["Cas_Observes"].shift(i).fillna(0)
        
        # Moyenne historique locale
        moyenne_historique = weekly_features.groupby("Aire_Sante")["Cas_Observes"].mean().reset_index()
        moyenne_historique.columns = ["Aire_Sante", "Moyenne_Historique"]
        weekly_features = weekly_features.merge(moyenne_historique, on="Aire_Sante", how="left")
        
        # 2. D√©finition des features pour le mod√®le
        feature_cols = [
            "Semaine_Epi", "Pop_Enfants", "Urban_Enc", "Taux_Vaccination",
            "Temperature_Moy", "Humidite_Moy", "Densite_Pop", "Moyenne_Historique",
            "Cas_Lag_1", "Cas_Lag_2", "Cas_Lag_3", "Cas_Lag_4"
        ]
        
        # Nettoyage des NaNs pour le training
        train_df = weekly_features.dropna(subset=["Cas_Observes"] + feature_cols)
        
        X = train_df[feature_cols]
        y = train_df["Cas_Observes"]
        
        # 3. Entra√Ænement du mod√®le s√©lectionn√©
        if modele_choisi == "GradientBoosting (Recommand√©)":
            model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)
        elif modele_choisi == "RandomForest":
            model = RandomForestRegressor(n_estimators=100, random_state=42)
        elif modele_choisi == "Ridge Regression":
            model = Ridge()
        elif modele_choisi == "Lasso Regression":
            model = Lasso()
        else:
            model = DecisionTreeRegressor()
            
        model.fit(X, y)
        
        # √âvaluation rapide (Cross-validation)
        cv_scores = cross_val_score(model, X, y, cv=5)
        cv_mean = cv_scores.mean()
        cv_std = cv_scores.std()
        
        # 4. Pr√©diction pour les semaines futures
        predictions_futures = []
        
        for aire in all_aires:
            aire_data = weekly_features[weekly_features["Aire_Sante"] == aire].iloc[-1:].copy()
            
            # √âtat initial pour la pr√©diction r√©cursive
            current_lags = [
                aire_data["Cas_Observes"].values[0],
                aire_data["Cas_Lag_1"].values[0],
                aire_data["Cas_Lag_2"].values[0],
                aire_data["Cas_Lag_3"].values[0]
            ]
            
            for w in range(1, n_weeks_pred + 1):
                futur_week = (derniere_semaine_epi + w - 1) % 52 + 1
                
                input_row = pd.DataFrame([{
                    "Semaine_Epi": futur_week,
                    "Pop_Enfants": aire_data["Pop_Enfants"].values[0],
                    "Urban_Enc": aire_data["Urban_Enc"].values[0],
                    "Taux_Vaccination": aire_data["Taux_Vaccination"].values[0],
                    "Temperature_Moy": aire_data["Temperature_Moy"].values[0],
                    "Humidite_Moy": aire_data["Humidite_Moy"].values[0],
                    "Densite_Pop": aire_data["Densite_Pop"].values[0],
                    "Moyenne_Historique": aire_data["Moyenne_Historique"].values[0],
                    "Cas_Lag_1": current_lags[0],
                    "Cas_Lag_2": current_lags[1],
                    "Cas_Lag_3": current_lags[2],
                    "Cas_Lag_4": current_lags[3]
                }])
                
                pred_val = model.predict(input_row[feature_cols])[0]
                pred_val = max(0, pred_val) # Pas de cas n√©gatifs
                
                predictions_futures.append({
                    "Aire_Sante": aire,
                    "Semaine_Epi": futur_week,
                    "Cas_Prevus": pred_val
                })
                
                # Update lags pour la semaine suivante
                current_lags = [pred_val] + current_lags[:3]
        
        df_pred = pd.DataFrame(predictions_futures)
        
        # 5. Calcul des Alertes et Risques
        # Agr√©gation des pr√©dictions par aire
        pred_agg = df_pred.groupby("Aire_Sante")["Cas_Prevus"].agg(['sum', 'mean', 'max']).reset_index()
        pred_agg.columns = ["Aire_Sante", "Total_Prevu", "Moyenne_Prevue", "Pic_Prevu"]
        
        # Jointure avec les donn√©es historiques et d√©mographiques
        resultats_finaux = pred_agg.merge(moyenne_historique, on="Aire_Sante")
        resultats_finaux = resultats_finaux.merge(
            sa_gdf_enrichi[["health_area", "Pop_Enfants", "Taux_Vaccination", "Urbanisation"]],
            left_on="Aire_Sante", right_on="health_area"
        )
        
        # Calcul du score de risque
        # Formule : (Evolution / Moyenne) * Poids + (Taux_Attaque_Prevu) * Poids
        resultats_finaux["Evolution_Pct"] = (
            (resultats_finaux["Moyenne_Prevue"] - resultats_finaux["Moyenne_Historique"]) / 
            resultats_finaux["Moyenne_Historique"].replace(0, 0.1) * 100
        )
        
        def determiner_risque(row):
            score = 0
            # Condition 1: Hausse massive par rapport √† l'historique
            if row["Evolution_Pct"] >= seuil_hausse: score += 2
            elif row["Evolution_Pct"] > 10: score += 1
            
            # Condition 2: Alerte √©pid√©mique (nombre absolu de cas)
            if row["Pic_Prevu"] >= seuil_alerte_epidemique: score += 3
            elif row["Pic_Prevu"] >= 2: score += 1
            
            # Condition 3: Facteurs de vuln√©rabilit√©
            if row["Taux_Vaccination"] < 80: score += 1
            
            if score >= 4: return "üî¥ √âlev√© (Alerte)"
            if score >= 2: return "üü† Mod√©r√©"
            return "üü¢ Faible"
            
        resultats_finaux["Niveau_Risque"] = resultats_finaux.apply(determiner_risque, axis=1)
        
        # --- AFFICHAGE DES R√âSULTATS ---
        st.success(f"‚úÖ Mod√©lisation termin√©e avec succ√®s ! (R¬≤ validation: {cv_mean:.3f})")
        
        col_res1, col_res2 = st.columns([1, 2])
        
        with col_res1:
            st.subheader("üö® Synth√®se des Alertes")
            alerte_counts = resultats_finaux["Niveau_Risque"].value_counts()
            for r_type, count in alerte_counts.items():
                st.write(f"**{r_type}**: {count} aires")
            
            st.dataframe(
                resultats_finaux[resultats_finaux["Niveau_Risque"].str.contains("√âlev√©|Mod√©r√©")]
                .sort_values("Pic_Prevu", ascending=False)
                [["Aire_Sante", "Pic_Prevu", "Evolution_Pct", "Niveau_Risque"]],
                hide_index=True
            )
            
        with col_res2:
            st.subheader("üìÖ Heatmap des Pr√©dictions")
            # Pivot pour la heatmap : Semaines en X, Aires en Y, Cas en couleur
            # On prend les 20 aires les plus √† risque
            top_aires = resultats_finaux.sort_values("Pic_Prevu", ascending=False).head(20)["Aire_Sante"].tolist()
            heatmap_data = df_pred[df_pred["Aire_Sante"].isin(top_aires)].pivot(
                index="Aire_Sante", columns="Semaine_Epi", values="Cas_Prevus"
            )
            fig_heat = px.imshow(
                heatmap_data, 
                labels=dict(x="Semaine √âpid√©miologique", y="Aire de Sant√©", color="Cas pr√©vus"),
                color_continuous_scale="YlOrRd"
            )
            st.plotly_chart(fig_heat, use_container_width=True)
            
        # Carte des pr√©dictions
        st.subheader("üó∫Ô∏è Carte des Pr√©dictions")

sa_gdf_pred = sa_gdf_enrichi.merge(
    risk_df,
    left_on="health_area",
    right_on="Aire_Sante",
    how="left"
)

sa_gdf_pred["Variation_Pct"] = sa_gdf_pred["Variation_Pct"].fillna(0)
sa_gdf_pred["Cas_Predits_Max"] = sa_gdf_pred["Cas_Predits_Max"].fillna(0)

m_pred = folium.Map(
    location=[center_lat, center_lon],
    zoom_start=6,
    tiles="CartoDB positron"
)

max_var = max(abs(sa_gdf_pred["Variation_Pct"].min()), abs(sa_gdf_pred["Variation_Pct"].max()))

colormap_pred = cm.LinearColormap(
    colors=['#2e7d32', '#81c784', '#e0e0e0', '#ff9800', '#d32f2f'],
    vmin=-max_var,
    vmax=max_var,
    caption="Variation (%) par rapport √† la moyenne"
)
colormap_pred.add_to(m_pred)

for idx, row in sa_gdf_pred.iterrows():
    aire_name = row['health_area']
    
    # V√©rifier que les colonnes existent avec get() pour √©viter KeyError
    variation_pct = row.get('Variation_Pct', 0)
    moy_historique = row.get('Moyenne_Historique', 0)
    cas_pred_moy = row.get('Cas_Predits_Moyen', 0)
    cas_pred_max = row.get('Cas_Predits_Max', 0)
    semaine_pic = row.get('Semaine_Pic', 'N/A')
    categorie = row.get('Categorie_Variation', 'N/A')
    
    popup_html = f"""
    <div style="font-family: Arial; width: 360px;">
        <h3 style="color: #1976d2; border-bottom: 2px solid #1976d2;">
            {aire_name}
        </h3>
        <div style="background-color: {'#ffebee' if variation_pct >= seuil_hausse else '#e8f5e9' if variation_pct <= -seuil_baisse else '#f5f5f5'}; padding: 10px; margin: 10px 0; border-radius: 5px;">
            <h4 style="margin: 0;">üîÆ Pr√©dictions</h4>
            <table style="width: 100%; margin-top: 5px;">
                <tr><td><b>Moyenne historique:</b></td><td style="text-align: right;">
                    {moy_historique:.1f} cas/sem
                </td></tr>
                <tr><td><b>Moyenne pr√©dite:</b></td><td style="text-align: right;">
                    {cas_pred_moy:.1f} cas/sem
                </td></tr>
                <tr><td><b>Variation:</b></td><td style="text-align: right; font-size: 18px; color: {'#d32f2f' if variation_pct >= seuil_hausse else '#2e7d32' if variation_pct <= -seuil_baisse else '#000'};">
                    <b>{variation_pct:+.1f}%</b>
                </td></tr>
                <tr><td>Tendance:</td><td style="text-align: right;">
                    <b>{categorie}</b>
                </td></tr>
                <tr><td>Semaine du pic:</td><td style="text-align: right;">
                    {semaine_pic}
                </td></tr>
                <tr><td>Pic maximal:</td><td style="text-align: right;">
                    {int(cas_pred_max)} cas
                </td></tr>
            </table>
        </div>
    </div>
    """
    
    fill_color = colormap_pred(variation_pct) if pd.notna(variation_pct) else '#e0e0e0'
    
    folium.GeoJson(
        row['geometry'],
        style_function=lambda x, color=fill_color: {
            'fillColor': color,
            'color': 'black',
            'weight': 0.5,
            'fillOpacity': 0.7
        },
        tooltip=folium.Tooltip(
            f"<b>{aire_name}</b><br>Variation: {variation_pct:+.1f}%",
            sticky=True
        ),
        popup=folium.Popup(popup_html, max_width=400)
    ).add_to(m_pred)

st_folium(m_pred, width=1400, height=650)
            
        st_folium(m_pred, width="100%", height=500, key="map_pred")
        
        # Export des r√©sultats
        csv_pred = resultats_finaux.to_csv(index=False).encode('utf-8')
        st.download_button(
            "üì• T√©l√©charger le rapport de pr√©diction (CSV)",
            csv_pred,
            "predictions_rougeole.csv",
            "text/csv",
            key='download-csv'
        )
        
        # Footer m√©thodologie
        st.markdown("---")
        st.caption(f"""
**M√©thodologie de pr√©diction:**
Mod√®le: {modele_choisi} | Score R¬≤ (validation crois√©e): {cv_mean:.3f} (¬±{cv_std:.3f}) |
Variables: {len(feature_cols)} features (historique 4 semaines, d√©mographie, urbanisation, climat, vaccination) |
P√©riode: S{derniere_semaine_epi+1} √† S{min(derniere_semaine_epi+n_weeks_pred, 52)} ({n_weeks_pred} semaines) |
Seuils: Baisse ‚â•{seuil_baisse}%, Hausse ‚â•{seuil_hausse}%, Alerte ‚â•{seuil_alerte_epidemique} cas/sem
        """)

else:
    st.info("üëÜ Cliquez sur le bouton ci-dessus pour lancer la mod√©lisation pr√©dictive")
    st.markdown("""
### üìö Ce que vous obtiendrez :
‚úÖ **Pr√©dictions par semaines √©pid√©miologiques** (S1 √† S52)
‚úÖ **Identification des aires √† risque** selon vos seuils personnalis√©s
‚úÖ **Heatmap temporelle** (√©volution semaine par semaine)
‚úÖ **Cartes interactives** avec pr√©dictions
‚úÖ **Export multi-formats** (CSV, Excel, GeoJSON)
‚úÖ **Recommandations op√©rationnelles** bas√©es sur les r√©sultats
‚úÖ **Int√©gration automatique** des donn√©es disponibles (climat, vaccination, d√©mographie)
    """)

# Footer global
st.markdown("---")
st.caption(f"Plateforme de Surveillance Rougeole Multi-pays | Donn√©es GEE, NASA, WorldPop | Actualis√© le {datetime.now().strftime('%d/%m/%Y %H:%M')}")
