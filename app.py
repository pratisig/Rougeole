# ============================================================
# APP SURVEILLANCE & PRÃ‰DICTION ROUGEOLE - VERSION 3.0
# PARTIE 1/6 - IMPORTS ET CONFIGURATION
# ============================================================

import streamlit as st
import pandas as pd
import numpy as np
import geopandas as gpd
from datetime import datetime, timedelta
import requests
from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor
from sklearn.linear_model import Ridge, Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split, cross_val_score
import ee
import json
import folium
from folium.plugins import HeatMap, MarkerCluster
from streamlit_folium import st_folium
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from io import BytesIO
import zipfile
import tempfile
import os
from shapely.geometry import shape
import warnings
warnings.filterwarnings('ignore')

# Configuration Streamlit
st.set_page_config(
    page_title="Surveillance Rougeole Multi-pays",
    layout="wide",
    page_icon="ğŸ¦ ",
    initial_sidebar_state="expanded"
)

# CSS personnalisÃ©
st.markdown("""
<style>
.metric-card{background-color:#f0f2f6;padding:15px;border-radius:10px;box-shadow:2px 2px 5px rgba(0,0,0,0.1)}
.high-risk{background-color:#ffebee;color:#c62828;font-weight:bold;padding:5px;border-radius:3px}
.medium-risk{background-color:#fff3e0;color:#ef6c00;padding:5px;border-radius:3px}
.low-risk{background-color:#e8f5e9;color:#2e7d32;padding:5px;border-radius:3px}
.stButton>button{width:100%}
h1{color:#d32f2f}
.info-box{background-color:#e3f2fd;padding:10px;border-left:4px solid #2196f3;margin:10px 0}
.model-hint{background-color:#fff9c4;padding:8px;border-radius:5px;font-size:0.9em;margin:5px 0}
.weight-box{background-color:#e8f5e9;padding:10px;border-radius:5px;margin:10px 0;border-left:4px solid #4caf50}
</style>
""", unsafe_allow_html=True)

st.title("ğŸ¦  Dashboard de Surveillance et PrÃ©diction - Rougeole")
st.markdown("### Analyse Ã©pidÃ©miologique et modÃ©lisation prÃ©dictive par semaines Ã©pidÃ©miologiques")

# Mapping pays ISO3
PAYS_ISO3_MAP = {
    "Niger": "ner",
    "Burkina Faso": "bfa",
    "Mali": "mli",
    "Mauritanie": "mrt"
}

# Initialisation Google Earth Engine
@st.cache_resource
def init_gee():
    try:
        key_dict = json.loads(st.secrets["GEE_SERVICE_ACCOUNT"])
        credentials = ee.ServiceAccountCredentials(
            key_dict["client_email"],
            key_data=json.dumps(key_dict)
        )
        ee.Initialize(credentials)
        return True
    except:
        try:
            ee.Initialize()
            return True
        except:
            return False

gee_ok = init_gee()
if gee_ok:
    st.sidebar.success("âœ“ GEE connectÃ©")

# Session state
if 'pays_precedent' not in st.session_state:
    st.session_state.pays_precedent = None
if 'sa_gdf_cache' not in st.session_state:
    st.session_state.sa_gdf_cache = None

# Configuration Sidebar
st.sidebar.header("ğŸ“‚ Configuration de l'Analyse")

# Mode dÃ©mo
st.sidebar.subheader("ğŸ¯ Mode d'utilisation")
mode_demo = st.sidebar.radio(
    "Choisissez votre mode",
    ["ğŸ“Š DonnÃ©es rÃ©elles", "ğŸ§ª Mode dÃ©mo (donnÃ©es simulÃ©es)"],
    help="Mode dÃ©mo : gÃ©nÃ¨re automatiquement des donnÃ©es fictives pour tester l'application"
)

# Aires de santÃ©
st.sidebar.subheader("ğŸ—ºï¸ Aires de SantÃ©")
option_aire = st.sidebar.radio(
    "Source des donnÃ©es gÃ©ographiques",
    ["Fichier local (ao_hlthArea.zip)", "Upload personnalisÃ©"],
    key='option_aire'
)

pays_selectionne = None
iso3_pays = None

if option_aire == "Fichier local (ao_hlthArea.zip)":
    pays_selectionne = st.sidebar.selectbox(
        "ğŸŒ SÃ©lectionner le pays",
        list(PAYS_ISO3_MAP.keys()),
        key='pays_select'
    )
    iso3_pays = PAYS_ISO3_MAP[pays_selectionne]
    
    pays_change = (st.session_state.pays_precedent != pays_selectionne)
    if pays_change:
        st.session_state.pays_precedent = pays_selectionne
        st.session_state.sa_gdf_cache = None
        st.rerun()

upload_file = None
if option_aire == "Upload personnalisÃ©":
    upload_file = st.sidebar.file_uploader(
        "Charger un fichier gÃ©ographique",
        type=["shp", "geojson", "zip"],
        help="Format : Shapefile ou GeoJSON avec colonnes 'iso3' et 'health_area'"
    )

# DonnÃ©es Ã©pidÃ©miologiques
st.sidebar.subheader("ğŸ“Š DonnÃ©es Ã‰pidÃ©miologiques")

if mode_demo == "ğŸ§ª Mode dÃ©mo (donnÃ©es simulÃ©es)":
    option_linelist = "DonnÃ©es fictives (test)"
    linelist_file = None
    vaccination_file = None
    st.sidebar.info("ğŸ“Š Mode dÃ©mo activÃ© - DonnÃ©es simulÃ©es")
else:
    linelist_file = st.sidebar.file_uploader(
        "ğŸ“‹ Linelists rougeole (CSV)",
        type=["csv"],
        help="Format : health_area, Semaine_Epi, Cas_Total OU Date_Debut_Eruption, Aire_Sante..."
    )
    
    vaccination_file = st.sidebar.file_uploader(
        "ğŸ’‰ Couverture vaccinale (CSV - optionnel)",
        type=["csv"],
        help="Format : health_area, Taux_Vaccination (en %)"
    )

# PÃ©riode d'analyse
st.sidebar.subheader("ğŸ“… PÃ©riode d'Analyse")
col1, col2 = st.sidebar.columns(2)
with col1:
    start_date = st.date_input(
        "Date dÃ©but",
        value=datetime(2024, 1, 1),
        key='start_date'
    )
with col2:
    end_date = st.date_input(
        "Date fin",
        value=datetime.today(),
        key='end_date'
    )

# ParamÃ¨tres de prÃ©diction
st.sidebar.subheader("ğŸ”® ParamÃ¨tres de PrÃ©diction")
pred_mois = st.sidebar.slider(
    "PÃ©riode de prÃ©diction (mois)",
    min_value=1,
    max_value=12,
    value=3,
    help="Nombre de mois Ã  prÃ©dire aprÃ¨s la derniÃ¨re semaine de donnÃ©es"
)
n_weeks_pred = pred_mois * 4

st.sidebar.info(f"ğŸ“† PrÃ©diction sur **{n_weeks_pred} semaines Ã©pidÃ©miologiques** (~{pred_mois} mois)")

# Choix du modÃ¨le
st.sidebar.subheader("ğŸ¤– ModÃ¨le de PrÃ©diction")

modele_choisi = st.sidebar.selectbox(
    "Choisissez votre algorithme",
    [
        "GradientBoosting (RecommandÃ©)",
        "RandomForest",
        "Ridge Regression",
        "Lasso Regression",
        "Decision Tree"
    ],
    help="SÃ©lectionnez l'algorithme de machine learning pour la prÃ©diction"
)

# Hints pour chaque modÃ¨le
model_hints = {
    "GradientBoosting (RecommandÃ©)": "ğŸ¯ **Gradient Boosting** : TrÃ¨s performant pour les sÃ©ries temporelles. Combine plusieurs modÃ¨les faibles pour crÃ©er un modÃ¨le fort. Excellent pour capturer les relations non-linÃ©aires. RecommandÃ© pour la surveillance Ã©pidÃ©miologique.",
    "RandomForest": "ğŸŒ³ **Random Forest** : Ensemble d'arbres de dÃ©cision. Robuste aux valeurs aberrantes et aux donnÃ©es manquantes. Bon pour les interactions complexes entre variables.",
    "Ridge Regression": "ğŸ“Š **Ridge Regression** : RÃ©gression linÃ©aire avec rÃ©gularisation L2. Simple et rapide. IdÃ©al pour relations linÃ©aires. Moins performant sur donnÃ©es non-linÃ©aires.",
    "Lasso Regression": "ğŸ¯ **Lasso Regression** : RÃ©gularisation L1 avec sÃ©lection automatique des variables. Utile quand beaucoup de variables peu importantes. Simplifie le modÃ¨le.",
    "Decision Tree": "ğŸŒ² **Decision Tree** : Arbre de dÃ©cision unique. Simple Ã  interprÃ©ter mais risque de sur-apprentissage. Moins robuste que les mÃ©thodes d'ensemble."
}

st.sidebar.markdown(f'<div class="model-hint">{model_hints[modele_choisi]}</div>', unsafe_allow_html=True)

# ========== SYSTÃˆME HYBRIDE D'IMPORTANCE DES VARIABLES ==========
st.sidebar.subheader("âš–ï¸ Importance des Variables")

mode_importance = st.sidebar.radio(
    "Mode de pondÃ©ration",
    ["ğŸ¤– Automatique (ML)", "ğŸ‘¨â€âš•ï¸ Manuel (Expert)"],
    help="Automatique : calculÃ© par le modÃ¨le ML | Manuel : poids dÃ©finis par expertise Ã©pidÃ©miologique"
)

poids_manuels = {}
poids_normalises = {}

if mode_importance == "ğŸ‘¨â€âš•ï¸ Manuel (Expert)":
    with st.sidebar.expander("âš™ï¸ Configurer les poids", expanded=True):
        st.markdown("**DÃ©finissez l'importance de chaque groupe de variables**")
        st.caption("Les poids seront automatiquement normalisÃ©s pour totaliser 100%")
        
        poids_manuels["Historique_Cas"] = st.slider(
            "ğŸ“ˆ Historique des cas (lags)",
            min_value=0,
            max_value=100,
            value=40,
            step=5,
            help="Importance des cas passÃ©s (4 derniÃ¨res semaines)"
        )
        
        poids_manuels["Vaccination"] = st.slider(
            "ğŸ’‰ Couverture vaccinale",
            min_value=0,
            max_value=100,
            value=35,
            step=5,
            help="Importance du taux de vaccination et non-vaccinÃ©s"
        )
        
        poids_manuels["Demographie"] = st.slider(
            "ğŸ‘¥ DÃ©mographie",
            min_value=0,
            max_value=100,
            value=15,
            step=5,
            help="Importance de la population et densitÃ©"
        )
        
        poids_manuels["Urbanisation"] = st.slider(
            "ğŸ™ï¸ Urbanisation",
            min_value=0,
            max_value=100,
            value=8,
            step=2,
            help="Importance du type d'habitat (urbain/rural)"
        )
        
        poids_manuels["Climat"] = st.slider(
            "ğŸŒ¡ï¸ Facteurs climatiques",
            min_value=0,
            max_value=100,
            value=2,
            step=1,
            help="Importance de la tempÃ©rature, humiditÃ©, saison"
        )
        
        # Calculer le total et normaliser
        total_poids = sum(poids_manuels.values())
        
        if total_poids > 0:
            for key in poids_manuels:
                poids_normalises[key] = poids_manuels[key] / total_poids
        
        # Afficher le rÃ©sumÃ©
        st.markdown("---")
        st.markdown("**ğŸ“Š RÃ©partition normalisÃ©e :**")
        for key, value in poids_normalises.items():
            st.markdown(f"â€¢ {key} : **{value*100:.1f}%**")
        
        if abs(total_poids - 100) > 5:
            st.info(f"â„¹ï¸ Total brut : {total_poids}% â†’ NormalisÃ© Ã  100%")
else:
    st.sidebar.info("Le modÃ¨le ML calculera automatiquement l'importance optimale de chaque variable")

# Seuils d'alerte
st.sidebar.subheader("âš™ï¸ Seuils d'Alerte")
with st.sidebar.expander("Configurer les seuils", expanded=False):
    seuil_baisse = st.slider(
        "Seuil de baisse significative (%)",
        min_value=10,
        max_value=90,
        value=75,
        step=5,
        help="Afficher les aires avec baisse â‰¥ X% par rapport Ã  la moyenne"
    )
    seuil_hausse = st.slider(
        "Seuil de hausse significative (%)",
        min_value=10,
        max_value=200,
        value=50,
        step=10,
        help="Afficher les aires avec hausse â‰¥ X% par rapport Ã  la moyenne"
    )
    seuil_alerte_epidemique = st.number_input(
        "Seuil d'alerte Ã©pidÃ©mique (cas/semaine)",
        min_value=1,
        max_value=100,
        value=5,
        help="Nombre de cas par semaine dÃ©clenchant une alerte"
    )

# Fonctions de chargement gÃ©ographique
@st.cache_data
def load_health_areas_from_zip(zip_path, iso3_filter):
    try:
        with tempfile.TemporaryDirectory() as tmpdir:
            with zipfile.ZipFile(zip_path, 'r') as z:
                z.extractall(tmpdir)
            
            shp_files = [f for f in os.listdir(tmpdir) if f.endswith('.shp')]
            if not shp_files:
                raise ValueError("Aucun fichier .shp trouvÃ© dans le ZIP")
            
            shp_path = os.path.join(tmpdir, shp_files[0])
            gdf_full = gpd.read_file(shp_path)
            
            iso3_col = None
            for col in ['iso3', 'ISO3', 'iso_code', 'ISO_CODE', 'country_iso', 'COUNTRY_ISO']:
                if col in gdf_full.columns:
                    iso3_col = col
                    break
            
            if iso3_col is None:
                st.warning(f"âš ï¸ Colonne ISO3 non trouvÃ©e. Colonnes : {list(gdf_full.columns)}")
                return gpd.GeoDataFrame()
            
            gdf = gdf_full[gdf_full[iso3_col] == iso3_filter].copy()
            
            if gdf.empty:
                st.warning(f"âš ï¸ Aucune aire de santÃ© pour {iso3_filter}")
                return gpd.GeoDataFrame()
            
            name_col = None
            for col in ['health_area', 'HEALTH_AREA', 'name_fr', 'name', 'NAME', 'nom', 'NOM', 'aire_sante']:
                if col in gdf.columns:
                    name_col = col
                    break
            
            if name_col:
                gdf['health_area'] = gdf[name_col]
            else:
                gdf['health_area'] = [f"Aire_{i+1}" for i in range(len(gdf))]
            
            gdf = gdf[gdf.geometry.is_valid]
            
            if gdf.crs is None:
                gdf.set_crs("EPSG:4326", inplace=True)
            elif gdf.crs.to_epsg() != 4326:
                gdf = gdf.to_crs("EPSG:4326")
            
            return gdf
            
    except Exception as e:
        st.error(f"âŒ Erreur ZIP : {e}")
        return gpd.GeoDataFrame()

def load_shapefile_from_upload(upload_file):
    try:
        if upload_file.name.endswith('.zip'):
            with tempfile.TemporaryDirectory() as tmpdir:
                zip_path = os.path.join(tmpdir, 'upload.zip')
                with open(zip_path, 'wb') as f:
                    f.write(upload_file.getvalue())
                
                with zipfile.ZipFile(zip_path, 'r') as z:
                    z.extractall(tmpdir)
                    shp_files = [f for f in os.listdir(tmpdir) if f.endswith('.shp')]
                    if shp_files:
                        gdf = gpd.read_file(os.path.join(tmpdir, shp_files[0]))
                    else:
                        raise ValueError("Aucun .shp trouvÃ©")
        else:
            gdf = gpd.read_file(upload_file)
        
        if "health_area" not in gdf.columns:
            for col in ["health_area", "HEALTH_AREA", "name_fr", "name", "NAME", "nom", "NOM"]:
                if col in gdf.columns:
                    gdf["health_area"] = gdf[col]
                    break
            else:
                gdf["health_area"] = [f"Aire_{i}" for i in range(len(gdf))]
        
        gdf = gdf[gdf.geometry.is_valid]
        
        if gdf.crs is None:
            gdf.set_crs("EPSG:4326", inplace=True)
        elif gdf.crs.to_epsg() != 4326:
            gdf = gdf.to_crs("EPSG:4326")
        
        return gdf
        
    except Exception as e:
        st.error(f"âŒ Erreur lecture : {e}")
        return gpd.GeoDataFrame()

# ============================================================
# PARTIE 2/6 - CHARGEMENT AIRES DE SANTÃ‰ ET DONNÃ‰ES DE CAS
# ============================================================

# Chargement des aires de santÃ©
if st.session_state.sa_gdf_cache is not None and option_aire == "Fichier local (ao_hlthArea.zip)":
    sa_gdf = st.session_state.sa_gdf_cache
    st.sidebar.success(f"âœ“ {len(sa_gdf)} aires chargÃ©es (cache)")
else:
    with st.spinner(f"ğŸ”„ Chargement des aires de santÃ©..."):
        if option_aire == "Fichier local (ao_hlthArea.zip)":
            zip_path = os.path.join("data", "ao_hlthArea.zip")
            if not os.path.exists(zip_path):
                st.error(f"âŒ Fichier non trouvÃ© : {zip_path}")
                st.info("ğŸ“ Placez 'ao_hlthArea.zip' dans le dossier 'data/'")
                st.stop()
            
            sa_gdf = load_health_areas_from_zip(zip_path, iso3_pays)
            
            if sa_gdf.empty:
                st.error(f"âŒ Impossible de charger {pays_selectionne} ({iso3_pays})")
                st.stop()
            else:
                st.sidebar.success(f"âœ“ {len(sa_gdf)} aires chargÃ©es ({iso3_pays})")
                st.session_state.sa_gdf_cache = sa_gdf
                
        elif option_aire == "Upload personnalisÃ©":
            if upload_file is None:
                st.warning("âš ï¸ Veuillez uploader un fichier")
                st.stop()
            else:
                sa_gdf = load_shapefile_from_upload(upload_file)
                if sa_gdf.empty:
                    st.error("âŒ Fichier invalide")
                    st.stop()
                else:
                    st.sidebar.success(f"âœ“ {len(sa_gdf)} aires chargÃ©es")
                    st.session_state.sa_gdf_cache = sa_gdf

if sa_gdf.empty or sa_gdf is None:
    st.error("âŒ Aucune aire chargÃ©e")
    st.stop()

# GÃ©nÃ©ration de donnÃ©es fictives
@st.cache_data
def generate_dummy_linelists(_sa_gdf, n=500, start=None, end=None):
    np.random.seed(42)
    
    if start is None:
        start = datetime(2024, 1, 1)
    if end is None:
        end = datetime.today()
    
    delta_days = (end - start).days
    dates = pd.to_datetime(start) + pd.to_timedelta(
        np.random.exponential(scale=delta_days/3, size=n).clip(0, delta_days).astype(int),
        unit="D"
    )
    
    df = pd.DataFrame({
        "ID_Cas": range(1, n+1),
        "Date_Debut_Eruption": dates,
        "Date_Notification": dates + pd.to_timedelta(np.random.poisson(3, n), unit="D"),
        "Aire_Sante": np.random.choice(_sa_gdf["health_area"].unique(), n),
        "Age_Mois": np.random.gamma(shape=2, scale=30, size=n).clip(6, 180).astype(int),
        "Statut_Vaccinal": np.random.choice(["Oui", "Non"], n, p=[0.55, 0.45]),
        "Sexe": np.random.choice(["M", "F"], n),
        "Issue": np.random.choice(["GuÃ©ri", "DÃ©cÃ©dÃ©", "Inconnu"], n, p=[0.92, 0.03, 0.05])
    })
    
    return df

@st.cache_data
def generate_dummy_vaccination(_sa_gdf):
    np.random.seed(42)
    
    return pd.DataFrame({
        "health_area": _sa_gdf["health_area"],
        "Taux_Vaccination": np.random.beta(a=8, b=2, size=len(_sa_gdf)) * 100
    })

# Chargement des donnÃ©es de cas
with st.spinner("ğŸ“¥ Chargement donnÃ©es de cas..."):
    if mode_demo == "ğŸ§ª Mode dÃ©mo (donnÃ©es simulÃ©es)":
        df = generate_dummy_linelists(sa_gdf, start=start_date, end=end_date)
        vaccination_df = generate_dummy_vaccination(sa_gdf)
        st.sidebar.info(f"ğŸ“Š {len(df)} cas simulÃ©s gÃ©nÃ©rÃ©s")
        
    else:
        if linelist_file is None:
            st.error("âŒ Veuillez uploader un fichier CSV de lineliste")
            st.stop()
            
        try:
            df_raw = pd.read_csv(linelist_file)
            
            if "Semaine_Epi" in df_raw.columns and "Cas_Total" in df_raw.columns:
                expanded_rows = []
                for _, row in df_raw.iterrows():
                    aire = row.get("health_area") or row.get("Aire_Sante") or row.get("name_fr")
                    semaine = int(row["Semaine_Epi"])
                    cas_total = int(row["Cas_Total"])
                    annee = row.get("Annee", 2024)
                    
                    base_date = datetime.strptime(f"{annee}-W{semaine:02d}-1", "%Y-W%W-%w")
                    
                    for i in range(cas_total):
                        expanded_rows.append({
                            "ID_Cas": len(expanded_rows) + 1,
                            "Date_Debut_Eruption": base_date + timedelta(days=np.random.randint(0, 7)),
                            "Date_Notification": base_date + timedelta(days=np.random.randint(0, 10)),
                            "Aire_Sante": aire,
                            "Age_Mois": 0,
                            "Statut_Vaccinal": "Inconnu",
                            "Sexe": "Inconnu",
                            "Issue": "Inconnu"
                        })
                
                df = pd.DataFrame(expanded_rows)
                
            elif "Date_Debut_Eruption" in df_raw.columns:
                df = df_raw.copy()
                
                for col in ["Date_Debut_Eruption", "Date_Notification"]:
                    if col in df.columns:
                        df[col] = pd.to_datetime(df[col], errors='coerce')
            else:
                st.error("âŒ Format CSV non reconnu")
                st.stop()
            
            st.sidebar.success(f"âœ“ {len(df)} cas chargÃ©s")
            
        except Exception as e:
            st.error(f"âŒ Erreur CSV : {e}")
            st.stop()
        
        if vaccination_file is not None:
            try:
                vaccination_df = pd.read_csv(vaccination_file)
                st.sidebar.success(f"âœ“ Couverture vaccinale chargÃ©e ({len(vaccination_df)} aires)")
            except Exception as e:
                st.sidebar.warning(f"âš ï¸ Erreur vaccination CSV : {e}")
                vaccination_df = None
        else:
            if "Statut_Vaccinal" in df.columns:
                vacc_by_area = df.groupby("Aire_Sante").agg({
                    "Statut_Vaccinal": lambda x: ((x == "Oui").sum() / len(x) * 100) if len(x) > 0 else 0
                }).reset_index()
                vacc_by_area.columns = ["health_area", "Taux_Vaccination"]
                vaccination_df = vacc_by_area
                st.sidebar.info("â„¹ï¸ Taux vaccination extrait de la linelist")
            else:
                vaccination_df = None
                st.sidebar.info("â„¹ï¸ Pas de donnÃ©es de vaccination")

# Filtrer par pÃ©riode

# Normaliser les noms de colonnes du DataFrame df
COLONNES_MAPPING = {
    # Colonne aire de santÃ©
    "Aire_Sante": ["Aire_Sante", "aire_sante", "health_area", "HEALTH_AREA", "name_fr", "NAME", "nom", "NOM"],
    # Colonne date de dÃ©but
    "Date_Debut_Eruption": ["Date_Debut_Eruption", "date_debut_eruption", "Date_Debut", "date_onset", "Date_Onset", "symptom_onset"],
    # Colonne date notification
    "Date_Notification": ["Date_Notification", "date_notification", "Date_Notif", "date_notif", "notification_date"],
    # Colonne ID cas
    "ID_Cas": ["ID_Cas", "id_cas", "ID", "id", "Case_ID", "case_id", "ID_cas"],
    # Colonne Ã¢ge
    "Age_Mois": ["Age_Mois", "age_mois", "Age", "age", "AGE", "Age_Months", "age_months"],
    # Colonne statut vaccinal
    "Statut_Vaccinal": ["Statut_Vaccinal", "statut_vaccinal", "Vaccin", "vaccin", "Vaccination_Status", "vaccination_status", "Vacc_Statut"],
    # Colonne sexe
    "Sexe": ["Sexe", "sexe", "Sex", "sex", "Gender", "gender"],
    # Colonne issue
    "Issue": ["Issue", "issue", "Outcome", "outcome", "OUTCOME"]
}

def normaliser_colonnes(dataframe, mapping):
    """Renommer les colonnes du dataframe selon le mapping standardisÃ©"""
    rename_dict = {}
    for col_standard, col_possibles in mapping.items():
        for col_possible in col_possibles:
            if col_possible in dataframe.columns and col_possible != col_standard:
                rename_dict[col_possible] = col_standard
                break
    if rename_dict:
        dataframe = dataframe.rename(columns=rename_dict)
    return dataframe

# Appliquer la normalisation
df = normaliser_colonnes(df, COLONNES_MAPPING)

# Si "ID_Cas" n'existe pas, en crÃ©er une
if "ID_Cas" not in df.columns:
    df["ID_Cas"] = range(1, len(df) + 1)

# Si "Aire_Sante" n'existe pas, essayer de la crÃ©er depuis sa_gdf
if "Aire_Sante" not in df.columns:
    # Chercher n'importe quelle colonne qui pourrait contenir un nom d'aire
    for col in df.columns:
        if df[col].dtype == object:
            # VÃ©rifier si les valeurs matchent avec les aires de santÃ©
            sample_values = set(df[col].dropna().unique())
            sa_values = set(sa_gdf["health_area"].unique())
            if len(sample_values.intersection(sa_values)) > 0:
                df["Aire_Sante"] = df[col]
                st.sidebar.info(f"â„¹ï¸ Colonne 'Aire_Sante' crÃ©Ã©e depuis '{col}'")
                break
    else:
        # Si rien ne match, assigner une aire par dÃ©faut
        df["Aire_Sante"] = sa_gdf["health_area"].iloc[0]
        st.sidebar.warning("âš ï¸ Aucune colonne aire trouvÃ©e, valeur par dÃ©faut assignÃ©e")

# VÃ©rifier et convertir les dates
if "Date_Debut_Eruption" in df.columns:
    df["Date_Debut_Eruption"] = pd.to_datetime(df["Date_Debut_Eruption"], errors='coerce')
else:
    # Chercher une colonne date
    for col in df.columns:
        try:
            test_dates = pd.to_datetime(df[col], errors='coerce')
            if test_dates.notna().sum() > len(df) * 0.5:  # Plus de 50% de dates valides
                df["Date_Debut_Eruption"] = test_dates
                st.sidebar.info(f"â„¹ï¸ 'Date_Debut_Eruption' crÃ©Ã©e depuis '{col}'")
                break
        except:
            continue
    else:
        # CrÃ©er une date par dÃ©faut
        df["Date_Debut_Eruption"] = pd.to_datetime(start_date)
        st.sidebar.warning("âš ï¸ Aucune colonne date trouvÃ©e, date de dÃ©but assignÃ©e par dÃ©faut")

if "Date_Notification" not in df.columns:
    # CrÃ©er Date_Notification = Date_Debut_Eruption + 3 jours par dÃ©faut
    df["Date_Notification"] = df["Date_Debut_Eruption"] + pd.to_timedelta(3, unit="D")

# Ajouter des colonnes optionnelles par dÃ©faut si absentes
if "Age_Mois" not in df.columns:
    df["Age_Mois"] = np.nan

if "Statut_Vaccinal" not in df.columns:
    df["Statut_Vaccinal"] = "Inconnu"

if "Sexe" not in df.columns:
    df["Sexe"] = "Inconnu"

if "Issue" not in df.columns:
    df["Issue"] = "Inconnu"

# Filtrer par pÃ©riode
df = df[
    (df["Date_Debut_Eruption"] >= pd.to_datetime(start_date)) &
    (df["Date_Debut_Eruption"] <= pd.to_datetime(end_date))
].copy()

if len(df) == 0:
    st.warning("âš ï¸ Aucun cas dans la pÃ©riode")
    st.stop()

# Calculer semaine Ã©pidÃ©miologique
def calculer_semaine_epidemio(date):
    return date.isocalendar()[1]

df['Semaine_Epi'] = df['Date_Debut_Eruption'].apply(calculer_semaine_epidemio)
df['Annee'] = df['Date_Debut_Eruption'].dt.year
df['Semaine_Annee'] = df['Annee'].astype(str) + '-S' + df['Semaine_Epi'].astype(str).str.zfill(2)

derniere_semaine_epi = df['Semaine_Epi'].max()
derniere_annee = df['Annee'].max()

st.sidebar.info(f"ğŸ“… DerniÃ¨re semaine : **S{derniere_semaine_epi}** ({derniere_annee})")
# ============================================================
# PARTIE 3/6 - ENRICHISSEMENT AVEC DONNÃ‰ES EXTERNES
# WorldPop, NASA POWER, GHSL
# ============================================================

# WorldPop - DonnÃ©es dÃ©mographiques
@st.cache_data
def worldpop_children_stats(_sa_gdf, use_gee):
    if not use_gee:
        st.sidebar.warning("âš ï¸ WorldPop : GEE indisponible")
        return pd.DataFrame({
            "health_area": _sa_gdf["health_area"],
            "Pop_Totale": [np.nan] * len(_sa_gdf),
            "Pop_Garcons": [np.nan] * len(_sa_gdf),
            "Pop_Filles": [np.nan] * len(_sa_gdf),
            "Pop_Enfants": [np.nan] * len(_sa_gdf)
        })
    
    try:
        progress_bar = st.sidebar.progress(0)
        status_text = st.sidebar.empty()
        
        status_text.text("ğŸ“¥ Chargement WorldPop...")
        dataset = ee.ImageCollection("WorldPop/GP/100m/pop_age_sex")
        pop_img = dataset.mosaic()
        
        # Bandes enfants 0-14 ans
        male_bands = ["M_0", "M_1", "M_5", "M_10"]
        female_bands = ["F_0", "F_1", "F_5", "F_10"]
        
        selected_males = pop_img.select(male_bands)
        selected_females = pop_img.select(female_bands)
        total_pop = pop_img.select(['population'])
        
        # ========== CALCUL DES SOMMES PAR SEXE ==========
        males_sum = selected_males.reduce(ee.Reducer.sum()).rename('garcons')
        females_sum = selected_females.reduce(ee.Reducer.sum()).rename('filles')
        enfants = males_sum.add(females_sum).rename('enfants')
        # ================================================
        
        # ========== MOSAÃQUE FINALE ==========
        # Option 1 (recommandÃ©e) : Garder population totale + dÃ©tails enfants
        #final_mosaic = total_pop.addBands(males_sum).addBands(females_sum).addBands(enfants)
        
        # Option 2 (si vous voulez SEULEMENT enfants, dÃ©commentez) :
        final_mosaic = males_sum.addBands(females_sum)
        # =====================================
        
        # Conversion densitÃ© â†’ compte absolu
        # WorldPop stocke personnes/pixel, on multiplie par aire du pixel
        pixel_area = ee.Image.pixelArea().divide(10000)  # Aire en unitÃ©s de 100mÂ²
        final_mosaic_count = final_mosaic.multiply(pixel_area)
        
        status_text.text("ğŸ—ºï¸ Conversion gÃ©omÃ©tries...")
        features = []
        for idx, row in _sa_gdf.iterrows():
            geom = row['geometry']
            props = {"health_area": row["health_area"]}
            
            if geom.geom_type == 'Polygon':
                coords = [[[x, y] for x, y in geom.exterior.coords]]
                ee_geom = ee.Geometry.Polygon(coords)
            elif geom.geom_type == 'MultiPolygon':
                coords = []
                for poly in geom.geoms:
                    coords.append([[[x, y] for x, y in poly.exterior.coords]])
                ee_geom = ee.Geometry.MultiPolygon(coords)
            else:
                continue
            
            features.append(ee.Feature(ee_geom, props))
        
        fc = ee.FeatureCollection(features)
        
        status_text.text("ğŸ”¢ Calcul statistiques zonales...")
        
        # ========== STATISTIQUES ZONALES (SOMME) ==========
        # Maintenant on somme les COMPTES ABSOLUS (pas les densitÃ©s)
        stats = final_mosaic_count.reduceRegions(
            collection=fc,
            reducer=ee.Reducer.sum(),
            scale=100,
            crs='EPSG:4326'
        )
        # ==================================================
        
        status_text.text("ğŸ“Š Extraction rÃ©sultats...")
        stats_info = stats.getInfo()
        
        data_list = []
        total_aires = len(stats_info['features'])
        
        for i, feat in enumerate(stats_info['features']):
            props = feat['properties']
            
            # ========== EXTRACTION VALEURS RÃ‰ELLES ==========
            pop_totale = props.get("population", 0)
            garcons = props.get("garcons", 0)
            filles = props.get("filles", 0)
            enfants_total = props.get("enfants", 0)
            # ================================================
            
            data_list.append({
                "health_area": props.get("health_area", ""),
                "Pop_Totale": int(pop_totale) if pop_totale > 0 else np.nan,
                "Pop_Garcons": int(garcons),
                "Pop_Filles": int(filles),
                "Pop_Enfants": int(enfants_total)
            })
            
            progress_value = min((i + 1) / total_aires, 1.0)
            progress_bar.progress(progress_value)
        
        progress_bar.empty()
        status_text.text("âœ… WorldPop terminÃ©")
        
        return pd.DataFrame(data_list)
        
    except Exception as e:
        st.sidebar.error(f"âŒ WorldPop : {str(e)}")
        if 'progress_bar' in locals():
            progress_bar.empty()
        if 'status_text' in locals():
            status_text.empty()
        return pd.DataFrame({
            "health_area": _sa_gdf["health_area"],
            "Pop_Totale": [np.nan] * len(_sa_gdf),
            "Pop_Garcons": [np.nan] * len(_sa_gdf),
            "Pop_Filles": [np.nan] * len(_sa_gdf),
            "Pop_Enfants": [np.nan] * len(_sa_gdf)
        })

# GHSL - Classification urbaine
@st.cache_data
def urban_classification(_sa_gdf, use_gee):
    if not use_gee:
        st.sidebar.warning("âš ï¸ GHSL : GEE indisponible")
        return pd.DataFrame({
            "health_area": _sa_gdf["health_area"],
            "Urbanisation": [np.nan] * len(_sa_gdf)
        })
    
    try:
        progress_bar = st.sidebar.progress(0)
        status_text = st.sidebar.empty()
        status_text.text("ğŸ™ï¸ Classification urbaine...")
        
        features = []
        for idx, row in _sa_gdf.iterrows():
            geom = row['geometry']
            props = {"health_area": row["health_area"]}
            
            if geom.geom_type == 'Polygon':
                coords = [[[x, y] for x, y in geom.exterior.coords]]
                ee_geom = ee.Geometry.Polygon(coords)
            elif geom.geom_type == 'MultiPolygon':
                coords = []
                for poly in geom.geoms:
                    coords.append([[[x, y] for x, y in poly.exterior.coords]])
                ee_geom = ee.Geometry.MultiPolygon(coords)
            else:
                continue
            
            features.append(ee.Feature(ee_geom, props))
        
        fc = ee.FeatureCollection(features)
        smod = ee.Image("JRC/GHSL/P2023A/GHS_SMOD/2020")
        
        def classify(feature):
            stats = smod.reduceRegion(
                ee.Reducer.mode(),
                feature.geometry(),
                scale=1000,
                maxPixels=1e9
            )
            smod_value = ee.Number(stats.get("smod_code")).toInt()
            urbanisation = ee.Algorithms.If(
                smod_value.gte(30),
                "Urbain",
                ee.Algorithms.If(smod_value.eq(23), "Semi-urbain", "Rural")
            )
            return feature.set({"Urbanisation": urbanisation})
        
        urban_fc = fc.map(classify)
        urban_info = urban_fc.getInfo()
        
        data_list = []
        total_aires = len(urban_info['features'])
        
        for i, feat in enumerate(urban_info['features']):
            props = feat['properties']
            data_list.append({
                "health_area": props.get("health_area", ""),
                "Urbanisation": props.get("Urbanisation", "Rural")
            })
            progress_value = min((i + 1) / total_aires, 1.0)
            progress_bar.progress(progress_value)
        
        progress_bar.empty()
        status_text.text("âœ… GHSL terminÃ©")
        
        return pd.DataFrame(data_list)
        
    except Exception as e:
        st.sidebar.error(f"âŒ GHSL : {str(e)}")
        if 'progress_bar' in locals():
            progress_bar.empty()
        if 'status_text' in locals():
            status_text.empty()
        return pd.DataFrame({
            "health_area": _sa_gdf["health_area"],
            "Urbanisation": [np.nan] * len(_sa_gdf)
        })

# NASA POWER - DonnÃ©es climatiques
@st.cache_data(ttl=86400)
def fetch_climate_nasa_power(_sa_gdf, start_date, end_date):
    progress_bar = st.sidebar.progress(0)
    status_text = st.sidebar.empty()
    
    data_list = []
    total_aires = len(_sa_gdf)
    
    for idx, row in _sa_gdf.iterrows():
        status_text.text(f"ğŸŒ¡ï¸ Climat {idx+1}/{total_aires}...")
        
        lat, lon = row.geometry.centroid.y, row.geometry.centroid.x
        
        url = "https://power.larc.nasa.gov/api/temporal/daily/point"
        params = {
            "parameters": "T2M,PRECTOTCORR,RH2M",
            "community": "AG",
            "longitude": lon,
            "latitude": lat,
            "start": start_date.strftime("%Y%m%d"),
            "end": end_date.strftime("%Y%m%d"),
            "format": "JSON"
        }
        
        try:
            r = requests.get(url, params=params, timeout=30)
            j = r.json()
            
            if "properties" in j and "parameter" in j["properties"]:
                p = j["properties"]["parameter"]
                
                temp_values = list(p.get("T2M", {}).values())
                rh_values = list(p.get("RH2M", {}).values())
                
                temp_mean = np.nanmean(temp_values) if temp_values else np.nan
                rh_mean = np.nanmean(rh_values) if rh_values else np.nan
                
                saison_seche_hum = rh_mean * 0.7 if not np.isnan(rh_mean) else np.nan
                
                data_list.append({
                    "health_area": row["health_area"],
                    "Temperature_Moy": temp_mean,
                    "Humidite_Moy": rh_mean,
                    "Saison_Seche_Humidite": saison_seche_hum
                })
            else:
                data_list.append({
                    "health_area": row["health_area"],
                    "Temperature_Moy": np.nan,
                    "Humidite_Moy": np.nan,
                    "Saison_Seche_Humidite": np.nan
                })
        except:
            data_list.append({
                "health_area": row["health_area"],
                "Temperature_Moy": np.nan,
                "Humidite_Moy": np.nan,
                "Saison_Seche_Humidite": np.nan
            })
        
        progress_value = min((idx + 1) / total_aires, 1.0)
        progress_bar.progress(progress_value)
    
    progress_bar.empty()
    status_text.text("âœ… Climat terminÃ©")
    
    return pd.DataFrame(data_list)

# Enrichissement du GeoDataFrame
with st.spinner("ğŸ”„ Enrichissement des donnÃ©es..."):
    pop_df = worldpop_children_stats(sa_gdf, gee_ok)
    urban_df = urban_classification(sa_gdf, gee_ok)
    climate_df = fetch_climate_nasa_power(sa_gdf, start_date, end_date)

sa_gdf_enrichi = sa_gdf.copy()
sa_gdf_enrichi = sa_gdf_enrichi.merge(pop_df, on="health_area", how="left")
sa_gdf_enrichi = sa_gdf_enrichi.merge(urban_df, on="health_area", how="left")
sa_gdf_enrichi = sa_gdf_enrichi.merge(climate_df, on="health_area", how="left")

if vaccination_df is not None:
    sa_gdf_enrichi = sa_gdf_enrichi.merge(vaccination_df, on="health_area", how="left")
else:
    sa_gdf_enrichi["Taux_Vaccination"] = np.nan

sa_gdf_enrichi["Superficie_km2"] = sa_gdf_enrichi.geometry.area / 1e6

sa_gdf_enrichi["Densite_Pop"] = (
    sa_gdf_enrichi["Pop_Totale"] / sa_gdf_enrichi["Superficie_km2"].replace(0, np.nan)
)

sa_gdf_enrichi["Densite_Enfants"] = (
    sa_gdf_enrichi["Pop_Enfants"] / sa_gdf_enrichi["Superficie_km2"].replace(0, np.nan)
)

sa_gdf_enrichi = sa_gdf_enrichi.replace([np.inf, -np.inf], np.nan)

st.sidebar.success("âœ“ Enrichissement terminÃ©")

st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ“‹ DonnÃ©es disponibles")

donnees_dispo = {
    "Population": not sa_gdf_enrichi["Pop_Totale"].isna().all(),
    "Urbanisation": not sa_gdf_enrichi["Urbanisation"].isna().all(),
    "Climat": not sa_gdf_enrichi["Humidite_Moy"].isna().all(),
    "Vaccination": not sa_gdf_enrichi["Taux_Vaccination"].isna().all()
}

for nom, dispo in donnees_dispo.items():
    icone = "âœ…" if dispo else "âŒ"
    st.sidebar.text(f"{icone} {nom}")

# ============================================================
# PARTIE 4/6 - KPIS, CARTE ET ANALYSES
# ============================================================

# KPIs
st.header("ğŸ“Š Indicateurs ClÃ©s de Performance")

col1, col2, col3, col4, col5 = st.columns(5)

with col1:
    st.metric("ğŸ“ˆ Cas totaux", f"{len(df):,}")

with col2:
    if "Statut_Vaccinal" in df.columns and df["Statut_Vaccinal"].notna().sum() > 0 and (df["Statut_Vaccinal"] != "Inconnu").sum() > 0:
        taux_non_vac = (df["Statut_Vaccinal"] == "Non").mean() * 100
        delta_vac = taux_non_vac - 45
        st.metric("ğŸ’‰ Non vaccinÃ©s", f"{taux_non_vac:.1f}%", delta=f"{delta_vac:+.1f}%")
    else:
        st.metric("ğŸ’‰ Non vaccinÃ©s", "N/A")

with col3:
    if "Age_Mois" in df.columns and df["Age_Mois"].notna().sum() > 0:
        age_median = df["Age_Mois"].median()
        st.metric("ğŸ‘¶ Ã‚ge mÃ©dian", f"{int(age_median)} mois")
    else:
        st.metric("ğŸ‘¶ Ã‚ge mÃ©dian", "N/A")

with col4:
    if "Issue" in df.columns and df["Issue"].notna().sum() > 0 and (df["Issue"] == "DÃ©cÃ©dÃ©").sum() > 0:
        taux_deces = (df["Issue"] == "DÃ©cÃ©dÃ©").mean() * 100
        st.metric("â˜ ï¸ LÃ©talitÃ©", f"{taux_deces:.2f}%")
    else:
        st.metric("â˜ ï¸ LÃ©talitÃ©", "N/A")

with col5:
    n_aires_touchees = df["Aire_Sante"].nunique()
    pct_aires = (n_aires_touchees / len(sa_gdf)) * 100
    st.metric("ğŸ—ºï¸ Aires touchÃ©es", f"{n_aires_touchees}/{len(sa_gdf)}", delta=f"{pct_aires:.0f}%")

# AgrÃ©gation par aire
agg_dict = {"ID_Cas": "count"}

if "Age_Mois" in df.columns:
    agg_dict["Age_Mois"] = "mean"

if "Statut_Vaccinal" in df.columns:
    agg_dict["Statut_Vaccinal"] = lambda x: (x == "Non").mean() * 100

cases_by_area = df.groupby("Aire_Sante").agg(agg_dict).reset_index()

# Renommer les colonnes selon ce qui est prÃ©sent
rename_map = {"ID_Cas": "Cas_Observes"}
if "Age_Mois" in cases_by_area.columns:
    rename_map["Age_Mois"] = "Age_Moyen"
if "Statut_Vaccinal" in cases_by_area.columns:
    rename_map["Statut_Vaccinal"] = "Taux_Non_Vaccines"

cases_by_area = cases_by_area.rename(columns=rename_map)

# Ajouter des colonnes par dÃ©faut si absentes
if "Taux_Non_Vaccines" not in cases_by_area.columns:
    cases_by_area["Taux_Non_Vaccines"] = 0
if "Age_Moyen" not in cases_by_area.columns:
    cases_by_area["Age_Moyen"] = 0

cases_by_area.columns = ["Aire_Sante", "Cas_Observes", "Taux_Non_Vaccines", "Age_Moyen"]

sa_gdf_with_cases = sa_gdf_enrichi.merge(
    cases_by_area,
    left_on="health_area",
    right_on="Aire_Sante",
    how="left"
)

sa_gdf_with_cases["Cas_Observes"] = sa_gdf_with_cases["Cas_Observes"].fillna(0)
sa_gdf_with_cases["Taux_Non_Vaccines"] = sa_gdf_with_cases["Taux_Non_Vaccines"].fillna(0)

sa_gdf_with_cases["Taux_Attaque_10000"] = (
    sa_gdf_with_cases["Cas_Observes"] /
    sa_gdf_with_cases["Pop_Enfants"].replace(0, np.nan) * 10000
).replace([np.inf, -np.inf], np.nan)

# Carte de situation actuelle
st.header("ğŸ—ºï¸ Cartographie de la Situation Actuelle")

center_lat = sa_gdf_with_cases.geometry.centroid.y.mean()
center_lon = sa_gdf_with_cases.geometry.centroid.x.mean()

m = folium.Map(
    location=[center_lat, center_lon],
    zoom_start=6,
    tiles="CartoDB positron",
    control_scale=True
)

import branca.colormap as cm

max_cases = sa_gdf_with_cases["Cas_Observes"].max()

if max_cases > 0:
    colormap = cm.LinearColormap(
        colors=['#e8f5e9', '#81c784', '#ffeb3b', '#ff9800', '#f44336', '#b71c1c'],
        vmin=0,
        vmax=max_cases,
        caption="Nombre de cas observÃ©s"
    )
    colormap.add_to(m)

for idx, row in sa_gdf_with_cases.iterrows():
    aire_name = row['health_area']
    cas_obs = int(row.get('Cas_Observes', 0))
    pop_enfants = row.get('Pop_Enfants', np.nan)
    taux_attaque = row.get('Taux_Attaque_10000', np.nan)
    urbanisation = row.get('Urbanisation', 'N/A')
    densite = row.get('Densite_Pop', np.nan)
    
    popup_html = f"""
    <div style="font-family: Arial; width: 350px;">
        <h3 style="margin-bottom: 10px; color: #1976d2; border-bottom: 2px solid #1976d2;">
            {aire_name}
        </h3>
        <div style="background-color: #f5f5f5; padding: 10px; margin: 10px 0; border-radius: 5px;">
            <h4 style="margin: 0; color: #d32f2f;">ğŸ“Š Situation Ã‰pidÃ©miologique</h4>
            <table style="width: 100%; margin-top: 5px;">
                <tr><td><b>Cas observÃ©s :</b></td><td style="text-align: right;">
                    <b style="font-size: 18px; color: #d32f2f;">{cas_obs}</b>
                </td></tr>
                <tr><td>Population enfants :</td><td style="text-align: right;">
                    {f"{int(pop_enfants):,}" if not np.isnan(pop_enfants) else "N/A"}
                </td></tr>
                <tr><td>Taux d'attaque :</td><td style="text-align: right;">
                    {f"{taux_attaque:.1f}/10K" if not np.isnan(taux_attaque) else "N/A"}
                </td></tr>
                <tr><td>Type habitat :</td><td style="text-align: right;">
                    <b>{urbanisation if pd.notna(urbanisation) else "N/A"}</b>
                </td></tr>
                <tr><td>DensitÃ© pop :</td><td style="text-align: right;">
                    {f"{densite:.1f} hab/kmÂ²" if not np.isnan(densite) else "N/A"}
                </td></tr>
            </table>
        </div>
    </div>
    """
    
    fill_color = colormap(row['Cas_Observes']) if max_cases > 0 else '#e0e0e0'
    
    if row['Cas_Observes'] >= seuil_alerte_epidemique:
        line_color = '#b71c1c'
        line_weight = 2
    else:
        line_color = 'black'
        line_weight = 0.5
    
    folium.GeoJson(
        row['geometry'],
        style_function=lambda x, color=fill_color, weight=line_weight, border=line_color: {
            'fillColor': color,
            'color': border,
            'weight': weight,
            'fillOpacity': 0.7
        },
        tooltip=folium.Tooltip(
            f"<b>{aire_name}</b><br>{cas_obs} cas",
            sticky=True
        ),
        popup=folium.Popup(popup_html, max_width=400)
    ).add_to(m)
    
    if cas_obs > 0:
        folium.Marker(
            location=[row.geometry.centroid.y, row.geometry.centroid.x],
            icon=folium.DivIcon(html=f"""
                <div style="
                    font-size: 9pt;
                    color: black;
                    font-weight: bold;
                    background-color: rgba(255, 255, 255, 0.85);
                    padding: 1px 4px;
                    border-radius: 3px;
                    white-space: nowrap;
                    border: 1px solid rgba(0, 0, 0, 0.2);
                    box-shadow: 0 1px 2px rgba(0,0,0,0.1);
                ">
                    {aire_name}
                </div>
            """)
        ).add_to(m)

heat_data = [
    [row.geometry.centroid.y, row.geometry.centroid.x, row['Cas_Observes']]
    for idx, row in sa_gdf_with_cases.iterrows()
    if row['Cas_Observes'] > 0
]

if heat_data:
    HeatMap(
        heat_data,
        radius=20,
        blur=25,
        max_zoom=13,
        gradient={0.0: 'blue', 0.5: 'yellow', 1.0: 'red'}
    ).add_to(m)

legend_html = f'''
<div style="
    position: fixed;
    bottom: 50px;
    left: 50px;
    width: 250px;
    background-color: white;
    border: 2px solid grey;
    z-index:9999;
    font-size:14px;
    padding: 10px;
    border-radius: 5px;">
    <p style="margin: 0; font-weight: bold;">ğŸ“Š LÃ©gende</p>
    <p style="margin: 5px 0;">
        <span style="background-color: #e8f5e9; padding: 2px 8px;">Faible</span>
        0-{max_cases//3:.0f} cas
    </p>
    <p style="margin: 5px 0;">
        <span style="background-color: #ffeb3b; padding: 2px 8px;">Moyen</span>
        {max_cases//3:.0f}-{2*max_cases//3:.0f} cas
    </p>
    <p style="margin: 5px 0;">
        <span style="background-color: #f44336; padding: 2px 8px; color: white;">Ã‰levÃ©</span>
        >{2*max_cases//3:.0f} cas
    </p>
    <p style="margin: 5px 0; padding-top: 5px; border-top: 1px solid #ccc;">
        <b>Seuil alerte :</b> {seuil_alerte_epidemique} cas/sem
    </p>
</div>
'''

m.get_root().html.add_child(folium.Element(legend_html))

st_folium(m, width=1400, height=650)

col1, col2, col3 = st.columns(3)

with col1:
    aires_alerte = len(sa_gdf_with_cases[sa_gdf_with_cases['Cas_Observes'] >= seuil_alerte_epidemique])
    st.metric("ğŸš¨ Aires en alerte", aires_alerte, f"{aires_alerte/len(sa_gdf)*100:.1f}%")

with col2:
    aires_sans_cas = len(sa_gdf_with_cases[sa_gdf_with_cases['Cas_Observes'] == 0])
    st.metric("âœ… Aires sans cas", aires_sans_cas, f"{aires_sans_cas/len(sa_gdf)*100:.1f}%")

with col3:
    densite_pop_moy = sa_gdf_with_cases['Densite_Pop'].mean()
    st.metric("ğŸ“ DensitÃ© pop. moy.", f"{densite_pop_moy:.1f} hab/kmÂ²")
# Analyse temporelle
st.header("ğŸ“ˆ Analyse Temporelle par Semaines Ã‰pidÃ©miologiques")

weekly_cases = df.groupby(['Annee', 'Semaine_Epi']).size().reset_index(name='Cas')
weekly_cases['Semaine_Label'] = weekly_cases['Annee'].astype(str) + '-S' + weekly_cases['Semaine_Epi'].astype(str).str.zfill(2)

fig_epi = go.Figure()

fig_epi.add_trace(go.Scatter(
    x=weekly_cases['Semaine_Label'],
    y=weekly_cases['Cas'],
    mode='lines+markers',
    name='Cas observÃ©s',
    line=dict(color='#d32f2f', width=3),
    marker=dict(size=6),
    hovertemplate='<b>%{x}</b><br>Cas : %{y}<extra></extra>'
))

from scipy.signal import savgol_filter

if len(weekly_cases) > 5:
    tendance = savgol_filter(
        weekly_cases['Cas'],
        window_length=min(7, len(weekly_cases) if len(weekly_cases) % 2 == 1 else len(weekly_cases)-1),
        polyorder=2
    )
    fig_epi.add_trace(go.Scatter(
        x=weekly_cases['Semaine_Label'],
        y=tendance,
        mode='lines',
        name='Tendance',
        line=dict(color='#1976d2', width=2, dash='dash'),
        hovertemplate='<b>%{x}</b><br>Tendance : %{y:.1f}<extra></extra>'
    ))

fig_epi.add_hline(
    y=seuil_alerte_epidemique,
    line_dash="dot",
    line_color="orange",
    annotation_text=f"Seuil d'alerte ({seuil_alerte_epidemique} cas/sem)",
    annotation_position="right"
)

fig_epi.update_layout(
    title="Courbe Ã©pidÃ©mique par semaines Ã©pidÃ©miologiques",
    xaxis_title="Semaine Ã©pidÃ©miologique",
    yaxis_title="Nombre de cas",
    hovermode='x unified',
    height=400
)

st.plotly_chart(fig_epi, use_container_width=True)

col1, col2, col3 = st.columns(3)

with col1:
    semaine_max = weekly_cases.loc[weekly_cases['Cas'].idxmax()]
    st.metric(
        "ğŸ”´ Semaine avec pic maximal",
        semaine_max['Semaine_Label'],
        f"{int(semaine_max['Cas'])} cas"
    )

with col2:
    cas_moyen_semaine = weekly_cases['Cas'].mean()
    st.metric("ğŸ“Š Moyenne hebdomadaire", f"{cas_moyen_semaine:.1f} cas")

with col3:
    if len(weekly_cases) >= 2:
        variation = weekly_cases.iloc[-1]['Cas'] - weekly_cases.iloc[-2]['Cas']
        cas_precedent = weekly_cases.iloc[-2]['Cas']
        pct_variation = (variation / cas_precedent * 100) if cas_precedent > 0 else 0
        st.metric("ğŸ“‰ Variation derniÃ¨re semaine", f"{int(variation):+d} cas", f"{pct_variation:+.1f}%")
    else:
        st.metric("ğŸ“‰ Variation derniÃ¨re semaine", "N/A")

# Distribution par Ã¢ge
st.subheader("ğŸ‘¶ Distribution par Tranches d'Ã‚ge")

if "Age_Mois" in df.columns:
    df["Tranche_Age"] = pd.cut(
        df["Age_Mois"],
        bins=[0, 12, 60, 120, 180],
        labels=["0-1 an", "1-5 ans", "5-10 ans", "10-15 ans"]
    )
    age_available = True
else:
    df["Tranche_Age"] = "Inconnu"
    age_available = False

agg_dict_age = {"ID_Cas": "count"}

if "Statut_Vaccinal" in df.columns:
    agg_dict_age["Statut_Vaccinal"] = lambda x: (x == "Non").mean() * 100

age_stats = df.groupby("Tranche_Age").agg(agg_dict_age).reset_index()

rename_map_age = {"ID_Cas": "Nombre_Cas"}
if "Statut_Vaccinal" in age_stats.columns:
    rename_map_age["Statut_Vaccinal"] = "Pct_Non_Vaccines"

age_stats = age_stats.rename(columns=rename_map_age)

if "Pct_Non_Vaccines" not in age_stats.columns:
    age_stats["Pct_Non_Vaccines"] = 0

col1, col2 = st.columns(2)

col1, col2 = st.columns(2)

with col1:
    if age_available:
        fig_age = px.bar(
            age_stats,
            x="Tranche_Age",
            y="Nombre_Cas",
            title="Cas par tranche d'Ã¢ge",
            color="Nombre_Cas",
            color_continuous_scale="Reds",
            text="Nombre_Cas"
        )
        fig_age.update_traces(textposition='outside')
        st.plotly_chart(fig_age, use_container_width=True)
    else:
        st.info("â„¹ï¸ DonnÃ©es d'Ã¢ge non disponibles")

with col2:
    if age_available and age_stats["Pct_Non_Vaccines"].sum() > 0:
        fig_vacc_age = px.bar(
            age_stats,
            x="Tranche_Age",
            y="Pct_Non_Vaccines",
            title="% non vaccinÃ©s par Ã¢ge",
            color="Pct_Non_Vaccines",
            color_continuous_scale="Oranges",
            text="Pct_Non_Vaccines"
        )
        fig_vacc_age.update_traces(texttemplate='%{text:.1f}%', textposition='outside')
        st.plotly_chart(fig_vacc_age, use_container_width=True)
    else:
        st.info("â„¹ï¸ DonnÃ©es de vaccination par Ã¢ge non disponibles")

# Nowcasting
st.subheader("â±ï¸ Nowcasting - Correction des DÃ©lais de Notification")

st.info("""
**Nowcasting (PrÃ©vision immÃ©diate) :** Technique d'ajustement permettant d'estimer le nombre rÃ©el de cas en tenant compte des dÃ©lais de notification.
""")

if "Date_Notification" in df.columns and "Date_Debut_Eruption" in df.columns:
    df["Delai_Notification"] = (df["Date_Notification"] - df["Date_Debut_Eruption"]).dt.days
    delai_available = True
else:
    df["Delai_Notification"] = 3  # Valeur par dÃ©faut
    delai_available = False

delai_moyen = df["Delai_Notification"].mean()
delai_median = df["Delai_Notification"].median()
delai_std = df["Delai_Notification"].std()

col1, col2, col3, col4 = st.columns(4)

with col1:
    st.metric("DÃ©lai moyen de notification", f"{delai_moyen:.1f} jours" if delai_available and not np.isnan(delai_moyen) else "N/A")

with col2:
    st.metric("DÃ©lai mÃ©dian", f"{delai_median:.0f} jours" if delai_available and not np.isnan(delai_median) else "N/A")

with col3:
    st.metric("Ã‰cart-type", f"{delai_std:.1f} jours" if delai_available and not np.isnan(delai_std) else "N/A")

with col4:
    derniere_semaine_label = weekly_cases.iloc[-1]['Semaine_Label']
    cas_derniere_semaine = int(weekly_cases.iloc[-1]['Cas'])
    if delai_available and not np.isnan(delai_moyen):
        facteur_correction = 1 + (delai_moyen / 7)
        cas_corriges = int(cas_derniere_semaine * facteur_correction)
        st.metric(
            f"Cas corrigÃ©s ({derniere_semaine_label})",
            cas_corriges,
            delta=f"+{cas_corriges - cas_derniere_semaine}"
        )
    else:
        st.metric(
            f"Cas corrigÃ©s ({derniere_semaine_label})",
            cas_derniere_semaine,
            delta="N/A"
        )

if delai_available:
    fig_delai = px.histogram(
        df,
        x="Delai_Notification",
        nbins=20,
        title="Distribution des dÃ©lais de notification",
        labels={"Delai_Notification": "DÃ©lai (jours)", "count": "Nombre de cas"},
        color_discrete_sequence=['#d32f2f']
    )

    fig_delai.add_vline(x=delai_moyen, line_dash="dash", line_color="blue", annotation_text=f"Moyenne : {delai_moyen:.1f}j")
    fig_delai.add_vline(x=delai_median, line_dash="dash", line_color="green", annotation_text=f"MÃ©diane : {delai_median:.0f}j")

    st.plotly_chart(fig_delai, use_container_width=True)
else:
    st.info("â„¹ï¸ DonnÃ©es de dÃ©lai de notification non disponibles")

# ============================================================
# PARTIE 5/6 - MODÃ‰LISATION PRÃ‰DICTIVE AVEC SYSTÃˆME HYBRIDE
# ============================================================

st.header("ğŸ”® ModÃ©lisation PrÃ©dictive par Semaines Ã‰pidÃ©miologiques")

st.markdown(f"""
<div class="info-box">
<b>Configuration de la prÃ©diction :</b><br>
- DerniÃ¨re semaine de donnÃ©es : <b>S{derniere_semaine_epi} ({derniere_annee})</b><br>
- PÃ©riode de prÃ©diction : <b>{pred_mois} mois ({n_weeks_pred} semaines)</b><br>
- Semaines prÃ©dites : <b>S{derniere_semaine_epi+1} Ã  S{min(derniere_semaine_epi+n_weeks_pred, 52)}</b><br>
- ModÃ¨le sÃ©lectionnÃ© : <b>{modele_choisi}</b><br>
- Mode importance : <b>{mode_importance}</b><br>
- Seuils configurÃ©s : Baisse â‰¥{seuil_baisse}%, Hausse â‰¥{seuil_hausse}%
</div>
""", unsafe_allow_html=True)

if 'prediction_lancee' not in st.session_state:
    st.session_state.prediction_lancee = False

col1, col2 = st.columns([3, 1])

with col1:
    if st.button("ğŸš€ Lancer la ModÃ©lisation PrÃ©dictive", type="primary", use_container_width=True):
        st.session_state.prediction_lancee = True
        st.rerun()

with col2:
    if st.button("ğŸ”„ RÃ©initialiser", use_container_width=True):
        st.session_state.prediction_lancee = False
        st.rerun()

if st.session_state.prediction_lancee:
    
    with st.spinner("ğŸ¤– PrÃ©paration des donnÃ©es et entraÃ®nement..."):
        
        weekly_features = df.groupby(["Aire_Sante", "Annee", "Semaine_Epi"]).agg(
            Cas_Observes=("ID_Cas", "count"),
            Non_Vaccines=("Statut_Vaccinal", lambda x: (x == "Non").mean() * 100),
            Age_Moyen=("Age_Mois", "mean")
        ).reset_index()
        
        weekly_features['Semaine_Label'] = (
            weekly_features['Annee'].astype(str) + '-S' +
            weekly_features['Semaine_Epi'].astype(str).str.zfill(2)
        )
        
        weekly_features = weekly_features.merge(
            sa_gdf_enrichi[[
                "health_area", "Pop_Totale", "Pop_Enfants",
                "Densite_Pop", "Densite_Enfants", "Urbanisation",
                "Temperature_Moy", "Humidite_Moy", "Saison_Seche_Humidite",
                "Taux_Vaccination"
            ]],
            left_on="Aire_Sante",
            right_on="health_area",
            how="left"
        )
        
        le_urban = LabelEncoder()
        weekly_features["Urban_Encoded"] = le_urban.fit_transform(
            weekly_features["Urbanisation"].fillna("Rural")
        )
        
        # CrÃ©er un coefficient climatique composite si donnÃ©es disponibles
        if donnees_dispo["Climat"]:
            scaler_climat = MinMaxScaler()
            climate_cols = ["Temperature_Moy", "Humidite_Moy", "Saison_Seche_Humidite"]
            
            for col in climate_cols:
                if col in weekly_features.columns:
                    weekly_features[f"{col}_Norm"] = scaler_climat.fit_transform(
                        weekly_features[[col]].fillna(weekly_features[col].mean())
                    )
            
            weekly_features["Coef_Climatique"] = (
                weekly_features.get("Temperature_Moy_Norm", 0) * 0.4 +
                weekly_features.get("Humidite_Moy_Norm", 0) * 0.4 +
                weekly_features.get("Saison_Seche_Humidite_Norm", 0) * 0.2
            )
        
        weekly_features = weekly_features.sort_values(['Aire_Sante', 'Annee', 'Semaine_Epi'])
        
        for lag in [1, 2, 3, 4]:
            weekly_features[f'Cas_Lag_{lag}'] = (
                weekly_features.groupby('Aire_Sante')['Cas_Observes'].shift(lag)
            )
        
        numeric_cols = weekly_features.select_dtypes(include=[np.number]).columns
        for col in numeric_cols:
            weekly_features[col] = weekly_features[col].replace([np.inf, -np.inf], 0)
            mean_val = weekly_features[col].mean()
            weekly_features[col] = weekly_features[col].fillna(mean_val if pd.notna(mean_val) else 0)
        
        st.subheader("ğŸ“š EntraÃ®nement du ModÃ¨le")
        
        # Construire la liste des features en fonction des donnÃ©es disponibles
        feature_cols = [
            "Cas_Observes", "Age_Moyen", "Semaine_Epi",
            "Cas_Lag_1", "Cas_Lag_2", "Cas_Lag_3", "Cas_Lag_4"
        ]
        
        # Mapping des groupes vers les colonnes individuelles
        feature_groups = {
            "Historique_Cas": ["Cas_Lag_1", "Cas_Lag_2", "Cas_Lag_3", "Cas_Lag_4"],
            "Vaccination": [],
            "Demographie": [],
            "Urbanisation": [],
            "Climat": []
        }
        
        if donnees_dispo["Population"]:
            feature_cols.extend(["Pop_Totale", "Pop_Enfants", "Densite_Pop", "Densite_Enfants"])
            feature_groups["Demographie"] = ["Pop_Totale", "Pop_Enfants", "Densite_Pop", "Densite_Enfants"]
            st.info("âœ… DonnÃ©es dÃ©mographiques intÃ©grÃ©es au modÃ¨le")
        
        if donnees_dispo["Urbanisation"]:
            feature_cols.append("Urban_Encoded")
            feature_groups["Urbanisation"] = ["Urban_Encoded"]
            st.info("âœ… Classification urbaine intÃ©grÃ©e au modÃ¨le")
        
        if donnees_dispo["Climat"]:
            feature_cols.append("Coef_Climatique")
            feature_groups["Climat"] = ["Coef_Climatique"]
            st.info("âœ… Coefficient climatique composite intÃ©grÃ© au modÃ¨le")
        
        if donnees_dispo["Vaccination"]:
            feature_cols.extend(["Taux_Vaccination", "Non_Vaccines"])
            feature_groups["Vaccination"] = ["Taux_Vaccination", "Non_Vaccines"]
            st.info("âœ… DonnÃ©es vaccinales intÃ©grÃ©es au modÃ¨le")
        elif "Non_Vaccines" in weekly_features.columns:
            feature_cols.append("Non_Vaccines")
            feature_groups["Vaccination"] = ["Non_Vaccines"]
        
        st.markdown(f"**Variables utilisÃ©es :** {len(feature_cols)} features")
        
        weekly_features_clean = weekly_features.dropna(subset=feature_cols)
        
        if len(weekly_features_clean) < 20:
            st.warning("âš ï¸ DonnÃ©es insuffisantes (minimum 20 observations requises)")
            st.stop()
        
        X = weekly_features_clean[feature_cols].copy()
        y = weekly_features_clean["Cas_Observes"]
        
        # ========== APPLICATION DES POIDS (MODE MANUEL) ==========
        if mode_importance == "ğŸ‘¨â€âš•ï¸ Manuel (Expert)":
            st.markdown('<div class="weight-box">', unsafe_allow_html=True)
            st.markdown("**âš–ï¸ Application des poids manuels aux variables**")
            
            # CrÃ©er un dictionnaire de mapping colonne â†’ poids
            column_weights = {}
            
            for group_name, weight in poids_normalises.items():
                if group_name in feature_groups:
                    cols_in_group = feature_groups[group_name]
                    if len(cols_in_group) > 0:
                        weight_per_col = weight / len(cols_in_group)
                        for col in cols_in_group:
                            if col in feature_cols:
                                column_weights[col] = weight_per_col
            
            # Ajouter des poids par dÃ©faut pour les colonnes non groupÃ©es
            for col in feature_cols:
                if col not in column_weights:
                    column_weights[col] = 0.01
            
            # Appliquer les poids aux features
            X_weighted = X.copy()
            for col in feature_cols:
                if col in column_weights:
                    X_weighted[col] = X_weighted[col] * column_weights[col]
            
            # Afficher le dÃ©tail des poids appliquÃ©s
            weights_df = pd.DataFrame({
                "Variable": list(column_weights.keys()),
                "Poids": [f"{v*100:.2f}%" for v in column_weights.values()]
            })
            
            col1, col2 = st.columns([2, 1])
            with col1:
                st.dataframe(weights_df, use_container_width=True, hide_index=True)
            with col2:
                st.metric("Total des poids", "100.00%")
            
            st.markdown('</div>', unsafe_allow_html=True)
            
            # Utiliser X_weighted pour l'entraÃ®nement
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X_weighted)
        else:
            # Mode automatique : pas de pondÃ©ration manuelle
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
        
        X_train, X_test, y_train, y_test = train_test_split(
            X_scaled, y, test_size=0.2, random_state=42
        )
        
        if modele_choisi == "GradientBoosting (RecommandÃ©)":
            model = GradientBoostingRegressor(
                n_estimators=300,
                learning_rate=0.05,
                max_depth=5,
                min_samples_split=4,
                random_state=42
            )
        elif modele_choisi == "RandomForest":
            model = RandomForestRegressor(
                n_estimators=200,
                max_depth=10,
                min_samples_split=4,
                random_state=42
            )
        elif modele_choisi == "Ridge Regression":
            model = Ridge(alpha=1.0, random_state=42)
        elif modele_choisi == "Lasso Regression":
            model = Lasso(alpha=0.1, random_state=42)
        elif modele_choisi == "Decision Tree":
            model = DecisionTreeRegressor(
                max_depth=8,
                min_samples_split=4,
                random_state=42
            )
        
        model.fit(X_train, y_train)
        
        score_test = model.score(X_test, y_test)
        cv_scores = cross_val_score(model, X_scaled, y, cv=5, scoring='r2')
        cv_mean = cv_scores.mean()
        cv_std = cv_scores.std()
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ğŸ“Š RÂ² Test", f"{score_test:.3f}")
        with col2:
            st.metric("ğŸ¯ RÂ² CV (5-fold)", f"{cv_mean:.3f}")
        with col3:
            st.metric("ğŸ“ Ã‰cart-type CV", f"Â±{cv_std:.3f}")
        
        if cv_mean > 0.7:
            st.success(f"âœ… ModÃ¨le performant ({modele_choisi})")
        elif cv_mean > 0.5:
            st.warning(f"âš ï¸ ModÃ¨le acceptable ({modele_choisi})")
        else:
            st.error(f"âŒ ModÃ¨le peu performant - envisagez un autre algorithme")
        
        # Afficher l'importance des variables (automatique OU ajustÃ©e)
        if hasattr(model, 'feature_importances_'):
            feature_importance = pd.DataFrame({
                "Variable": feature_cols,
                "Importance": model.feature_importances_
            }).sort_values("Importance", ascending=False)
            
            with st.expander("ğŸ“Š Importance des variables", expanded=True):
                if mode_importance == "ğŸ‘¨â€âš•ï¸ Manuel (Expert)":
                    st.info("â„¹ï¸ Ces importances reflÃ¨tent l'influence des variables **aprÃ¨s application des poids manuels**")
                else:
                    st.info("â„¹ï¸ Ces importances sont **calculÃ©es automatiquement** par le modÃ¨le ML")
                
                fig_imp = px.bar(
                    feature_importance.head(10),
                    x="Importance",
                    y="Variable",
                    orientation="h",
                    title="Top 10 variables les plus importantes",
                    color="Importance",
                    color_continuous_scale="Viridis"
                )
                st.plotly_chart(fig_imp, use_container_width=True)
        
        st.subheader(f"ğŸ“… GÃ©nÃ©ration des PrÃ©dictions - {n_weeks_pred} Semaines")
        
        future_climate = None
        if donnees_dispo["Climat"]:
            future_start = end_date + timedelta(days=1)
            future_end = end_date + timedelta(days=n_weeks_pred * 7)
            
            with st.spinner("ğŸŒ¡ï¸ Chargement prÃ©visions climatiques..."):
                try:
                    future_climate = fetch_climate_nasa_power(sa_gdf, future_start, future_end)
                    st.info("âœ… PrÃ©visions climatiques intÃ©grÃ©es aux prÃ©dictions")
                except:
                    st.warning("âš ï¸ PrÃ©visions climatiques indisponibles - utilisation valeurs moyennes")
        
        future_predictions = []
        
        for aire in weekly_features["Aire_Sante"].unique():
            aire_data = weekly_features[weekly_features["Aire_Sante"] == aire].sort_values(['Annee', 'Semaine_Epi'])
            
            if aire_data.empty:
                continue
            
            last_obs = aire_data.iloc[-1]
            
            last_4_weeks = aire_data.tail(4)['Cas_Observes'].values
            if len(last_4_weeks) < 4:
                last_4_weeks = np.pad(last_4_weeks, (4-len(last_4_weeks), 0), 'edge')
            
            for i in range(1, n_weeks_pred + 1):
                nouvelle_semaine_epi = (derniere_semaine_epi + i - 1) % 52 + 1
                nouvelle_annee = derniere_annee + ((derniere_semaine_epi + i - 1) // 52)
                
                future_row = {
                    "Aire_Sante": aire,
                    "Annee": nouvelle_annee,
                    "Semaine_Epi": nouvelle_semaine_epi,
                    "Semaine_Label": f"{nouvelle_annee}-S{str(nouvelle_semaine_epi).zfill(2)}",
                    "Age_Moyen": last_obs["Age_Moyen"]
                }
                
                if donnees_dispo["Population"]:
                    future_row.update({
                        "Pop_Totale": last_obs["Pop_Totale"],
                        "Pop_Enfants": last_obs["Pop_Enfants"],
                        "Densite_Pop": last_obs["Densite_Pop"],
                        "Densite_Enfants": last_obs["Densite_Enfants"]
                    })
                
                if donnees_dispo["Urbanisation"]:
                    future_row["Urban_Encoded"] = last_obs["Urban_Encoded"]
                
                if donnees_dispo["Climat"]:
                    if future_climate is not None:
                        climate_aire = future_climate[future_climate["health_area"] == aire]
                        if not climate_aire.empty:
                            temp_norm = scaler_climat.transform([[climate_aire.iloc[0]["Temperature_Moy"]]])[0][0]
                            hum_norm = scaler_climat.transform([[climate_aire.iloc[0]["Humidite_Moy"]]])[0][0]
                            saison_norm = scaler_climat.transform([[climate_aire.iloc[0]["Saison_Seche_Humidite"]]])[0][0]
                            
                            future_row["Coef_Climatique"] = temp_norm * 0.4 + hum_norm * 0.4 + saison_norm * 0.2
                        else:
                            future_row["Coef_Climatique"] = last_obs.get("Coef_Climatique", 0)
                    else:
                        future_row["Coef_Climatique"] = last_obs.get("Coef_Climatique", 0)
                
                if donnees_dispo["Vaccination"]:
                    future_row["Taux_Vaccination"] = last_obs["Taux_Vaccination"]
                    future_row["Non_Vaccines"] = last_obs["Non_Vaccines"]
                elif "Non_Vaccines" in last_obs:
                    future_row["Non_Vaccines"] = last_obs["Non_Vaccines"]
                
                if i == 1:
                    future_row["Cas_Observes"] = last_obs["Cas_Observes"]
                    future_row["Cas_Lag_1"] = last_4_weeks[-1]
                    future_row["Cas_Lag_2"] = last_4_weeks[-2] if len(last_4_weeks) >= 2 else last_4_weeks[-1]
                    future_row["Cas_Lag_3"] = last_4_weeks[-3] if len(last_4_weeks) >= 3 else last_4_weeks[-1]
                    future_row["Cas_Lag_4"] = last_4_weeks[-4] if len(last_4_weeks) >= 4 else last_4_weeks[-1]
                else:
                    prev_predictions = [
                        p["Predicted_Cases"] for p in future_predictions
                        if p["Aire_Sante"] == aire
                    ]
                    future_row["Cas_Observes"] = prev_predictions[-1] if prev_predictions else last_obs["Cas_Observes"]
                    future_row["Cas_Lag_1"] = prev_predictions[-1] if len(prev_predictions) >= 1 else last_4_weeks[-1]
                    future_row["Cas_Lag_2"] = prev_predictions[-2] if len(prev_predictions) >= 2 else last_4_weeks[-2]
                    future_row["Cas_Lag_3"] = prev_predictions[-3] if len(prev_predictions) >= 3 else last_4_weeks[-3]
                    future_row["Cas_Lag_4"] = prev_predictions[-4] if len(prev_predictions) >= 4 else last_4_weeks[-4]
                
                X_future = np.array([[future_row[col] for col in feature_cols]])
                
                # Appliquer les mÃªmes poids si mode manuel
                if mode_importance == "ğŸ‘¨â€âš•ï¸ Manuel (Expert)":
                    for idx, col in enumerate(feature_cols):
                        if col in column_weights:
                            X_future[0, idx] = X_future[0, idx] * column_weights[col]
                
                X_future_scaled = scaler.transform(X_future)
                
                predicted_cases = max(0, model.predict(X_future_scaled)[0])
                
                if cv_std > 0:
                    noise = np.random.normal(0, predicted_cases * cv_std * 0.1)
                    predicted_cases = max(0, predicted_cases + noise)
                
                future_row["Predicted_Cases"] = predicted_cases
                future_predictions.append(future_row)
        
        future_df = pd.DataFrame(future_predictions)
        
        st.success(f"âœ“ {len(future_df)} prÃ©dictions gÃ©nÃ©rÃ©es ({len(future_df['Aire_Sante'].unique())} aires Ã— {n_weeks_pred} semaines)")
        
        moyenne_historique = weekly_features.groupby("Aire_Sante")["Cas_Observes"].mean().reset_index()
        moyenne_historique.columns = ["Aire_Sante", "Moyenne_Historique"]
        
        risk_df = future_df.groupby("Aire_Sante").agg(
            Cas_Predits_Total=("Predicted_Cases", "sum"),
            Cas_Predits_Max=("Predicted_Cases", "max"),
            Cas_Predits_Moyen=("Predicted_Cases", "mean"),
            Semaine_Pic=("Predicted_Cases", lambda x: future_df.loc[x.idxmax(), "Semaine_Label"] if len(x) > 0 else "N/A")
        ).reset_index()
        
        risk_df = risk_df.merge(moyenne_historique, on="Aire_Sante", how="left")
        
        risk_df["Variation_Pct"] = (
            (risk_df["Cas_Predits_Moyen"] - risk_df["Moyenne_Historique"]) /
            risk_df["Moyenne_Historique"].replace(0, 1)
        ) * 100
        
        risk_df["Categorie_Variation"] = pd.cut(
            risk_df["Variation_Pct"],
            bins=[-np.inf, -seuil_baisse, -10, 10, seuil_hausse, np.inf],
            labels=["Forte baisse", "Baisse modÃ©rÃ©e", "Stable", "Hausse modÃ©rÃ©e", "Forte hausse"]
        )
        
        risk_df = risk_df.sort_values("Variation_Pct", ascending=False)

# ============================================================
# PARTIE 6/6 - VISUALISATIONS FINALES ET EXPORTS
# ============================================================

        st.subheader("ğŸ“Š SynthÃ¨se des PrÃ©dictions")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            total_predits = risk_df["Cas_Predits_Total"].sum()
            st.metric("Total cas prÃ©dits", f"{int(total_predits):,}")
        
        with col2:
            aires_hausse = len(risk_df[risk_df["Variation_Pct"] >= seuil_hausse])
            st.metric("ğŸ”´ Aires en hausse", aires_hausse, f"â‰¥{seuil_hausse}%")
        
        with col3:
            aires_baisse = len(risk_df[risk_df["Variation_Pct"] <= -seuil_baisse])
            st.metric("ğŸŸ¢ Aires en baisse", aires_baisse, f"â‰¥{seuil_baisse}%")
        
        with col4:
            aires_stables = len(risk_df[(risk_df["Variation_Pct"] > -10) & (risk_df["Variation_Pct"] < 10)])
            st.metric("âšª Aires stables", aires_stables, "Â±10%")
        
        fig_var_dist = px.pie(
            risk_df,
            names="Categorie_Variation",
            title="Distribution des tendances prÃ©dites",
            color="Categorie_Variation",
            color_discrete_map={
                "Forte baisse": "#2e7d32",
                "Baisse modÃ©rÃ©e": "#81c784",
                "Stable": "#9e9e9e",
                "Hausse modÃ©rÃ©e": "#ff9800",
                "Forte hausse": "#d32f2f"
            }
        )
        st.plotly_chart(fig_var_dist, use_container_width=True)
        
        st.subheader("ğŸ”¥ Heatmap Temporelle des PrÃ©dictions")
        
        top_10_hausse = risk_df.head(10)["Aire_Sante"].tolist()
        top_10_baisse = risk_df.tail(10)["Aire_Sante"].tolist()
        
        heatmap_data = future_df.pivot(
            index="Aire_Sante",
            columns="Semaine_Label",
            values="Predicted_Cases"
        ).fillna(0)
        
        col_heat1, col_heat2 = st.columns(2)
        
        with col_heat1:
            st.markdown("**ğŸ”´ Top 10 - Hausses prÃ©dites**")
            heatmap_hausse = heatmap_data.loc[heatmap_data.index.isin(top_10_hausse)]
            
            fig_heat_hausse = px.imshow(
                heatmap_hausse,
                labels=dict(x="Semaine", y="Aire", color="Cas"),
                x=heatmap_hausse.columns,
                y=heatmap_hausse.index,
                color_continuous_scale=["#ffebee", "#ffcdd2", "#ef9a9a", "#e57373", "#ef5350", "#f44336", "#d32f2f"],
                aspect="auto"
            )
            fig_heat_hausse.update_xaxes(side="bottom", tickangle=-45)
            fig_heat_hausse.update_layout(height=400)
            st.plotly_chart(fig_heat_hausse, use_container_width=True)
        
        with col_heat2:
            st.markdown("**ğŸŸ¢ Top 10 - Baisses prÃ©dites**")
            heatmap_baisse = heatmap_data.loc[heatmap_data.index.isin(top_10_baisse)]
            
            fig_heat_baisse = px.imshow(
                heatmap_baisse,
                labels=dict(x="Semaine", y="Aire", color="Cas"),
                x=heatmap_baisse.columns,
                y=heatmap_baisse.index,
                color_continuous_scale=["#e8f5e9", "#c8e6c9", "#a5d6a7", "#81c784", "#66bb6a", "#4caf50", "#2e7d32"],
                aspect="auto"
            )
            fig_heat_baisse.update_xaxes(side="bottom", tickangle=-45)
            fig_heat_baisse.update_layout(height=400)
            st.plotly_chart(fig_heat_baisse, use_container_width=True)
        
        tab1, tab2, tab3 = st.tabs([
            f"ğŸ”´ Hausse â‰¥{seuil_hausse}%",
            f"ğŸŸ¢ Baisse â‰¥{seuil_baisse}%",
            "ğŸ“Š Toutes les aires"
        ])
        
        with tab1:
            st.subheader(f"Aires avec Hausse Significative (â‰¥{seuil_hausse}%)")
            hausse_df = risk_df[risk_df["Variation_Pct"] >= seuil_hausse].copy()
            
            if len(hausse_df) > 0:
                def highlight_hausse(row):
                    return ["background-color: #ffcdd2"] * len(row)
                
                st.dataframe(
                    hausse_df[[
                        "Aire_Sante", "Moyenne_Historique", "Cas_Predits_Moyen",
                        "Variation_Pct", "Semaine_Pic", "Cas_Predits_Max"
                    ]].style.apply(highlight_hausse, axis=1).format({
                        "Moyenne_Historique": "{:.1f}",
                        "Cas_Predits_Moyen": "{:.1f}",
                        "Variation_Pct": "{:+.1f}%",
                        "Cas_Predits_Max": "{:.0f}"
                    }),
                    use_container_width=True
                )
                
                st.warning(f"âš ï¸ **{len(hausse_df)} aire(s)** nÃ©cessite(nt) une vigilance accrue")
            else:
                st.success("âœ“ Aucune aire avec hausse significative")
        
        with tab2:
            st.subheader(f"Aires avec Baisse Significative (â‰¥{seuil_baisse}%)")
            baisse_df = risk_df[risk_df["Variation_Pct"] <= -seuil_baisse].copy()
            
            if len(baisse_df) > 0:
                def highlight_baisse(row):
                    return ["background-color: #c8e6c9"] * len(row)
                
                st.dataframe(
                    baisse_df[[
                        "Aire_Sante", "Moyenne_Historique", "Cas_Predits_Moyen",
                        "Variation_Pct", "Semaine_Pic", "Cas_Predits_Max"
                    ]].style.apply(highlight_baisse, axis=1).format({
                        "Moyenne_Historique": "{:.1f}",
                        "Cas_Predits_Moyen": "{:.1f}",
                        "Variation_Pct": "{:+.1f}%",
                        "Cas_Predits_Max": "{:.0f}"
                    }),
                    use_container_width=True
                )
                
                st.success(f"âœ“ **{len(baisse_df)} aire(s)** montre(nt) une amÃ©lioration")
            else:
                st.info("â„¹ï¸ Aucune aire avec baisse significative")
        
        with tab3:
            st.subheader("Tableau Complet des PrÃ©dictions")
            
            def highlight_all(row):
                if row["Variation_Pct"] >= seuil_hausse:
                    return ["background-color: #ffcdd2"] * len(row)
                elif row["Variation_Pct"] <= -seuil_baisse:
                    return ["background-color: #c8e6c9"] * len(row)
                else:
                    return [""] * len(row)
            
            st.dataframe(
                risk_df[[
                    "Aire_Sante", "Moyenne_Historique", "Cas_Predits_Moyen",
                    "Variation_Pct", "Categorie_Variation", "Semaine_Pic", "Cas_Predits_Max"
                ]].style.apply(highlight_all, axis=1).format({
                    "Moyenne_Historique": "{:.1f}",
                    "Cas_Predits_Moyen": "{:.1f}",
                    "Variation_Pct": "{:+.1f}%",
                    "Cas_Predits_Max": "{:.0f}"
                }),
                use_container_width=True,
                height=400
            )
        
        st.subheader("ğŸ—ºï¸ Carte des PrÃ©dictions")
        
        sa_gdf_pred = sa_gdf_enrichi.merge(
            risk_df,
            left_on="health_area",
            right_on="Aire_Sante",
            how="left"
        )
        
        sa_gdf_pred["Variation_Pct"] = sa_gdf_pred["Variation_Pct"].fillna(0)
        sa_gdf_pred["Cas_Predits_Max"] = sa_gdf_pred["Cas_Predits_Max"].fillna(0)
        
        m_pred = folium.Map(
            location=[center_lat, center_lon],
            zoom_start=6,
            tiles="CartoDB positron"
        )
        
        max_var = max(abs(sa_gdf_pred["Variation_Pct"].min()), abs(sa_gdf_pred["Variation_Pct"].max()))
        
        colormap_pred = cm.LinearColormap(
            colors=['#2e7d32', '#81c784', '#e0e0e0', '#ff9800', '#d32f2f'],
            vmin=-max_var,
            vmax=max_var,
            caption="Variation (%) par rapport Ã  la moyenne"
        )
        colormap_pred.add_to(m_pred)
        
        for idx, row in sa_gdf_pred.iterrows():
            aire_name = row.get('health_area', 'Aire inconnue')
            variation_pct = row.get('Variation_Pct', 0)
            moy_historique = row.get('Moyenne_Historique', 0)
            cas_pred_moy = row.get('Cas_Predits_Moyen', 0)
            cas_pred_max = row.get('Cas_Predits_Max', 0)
            semaine_pic = row.get('Semaine_Pic', 'N/A')
            categorie = row.get('Categorie_Variation', 'N/A')
            
            if variation_pct >= seuil_hausse:
                bg_color = '#ffebee'
                var_color = '#d32f2f'
            elif variation_pct <= -seuil_baisse:
                bg_color = '#e8f5e9'
                var_color = '#2e7d32'
            else:
                bg_color = '#f5f5f5'
                var_color = '#000'
            
            popup_html = f"""
            <div style="font-family: Arial; width: 360px;">
                <h3 style="color: #1976d2; border-bottom: 2px solid #1976d2;">
                    {aire_name}
                </h3>
                <div style="background-color: {bg_color}; padding: 10px; margin: 10px 0; border-radius: 5px;">
                    <h4 style="margin: 0;">ğŸ”® PrÃ©dictions</h4>
                    <table style="width: 100%; margin-top: 5px;">
                        <tr><td><b>Moyenne historique :</b></td><td style="text-align: right;">
                            {moy_historique:.1f} cas/sem
                        </td></tr>
                        <tr><td><b>Moyenne prÃ©dite :</b></td><td style="text-align: right;">
                            {cas_pred_moy:.1f} cas/sem
                        </td></tr>
                        <tr><td><b>Variation :</b></td><td style="text-align: right; font-size: 18px; color: {var_color};">
                            <b>{variation_pct:+.1f}%</b>
                        </td></tr>
                        <tr><td>Tendance :</td><td style="text-align: right;">
                            <b>{categorie}</b>
                        </td></tr>
                        <tr><td>Semaine du pic :</td><td style="text-align: right;">
                            {semaine_pic}
                        </td></tr>
                        <tr><td>Pic maximal :</td><td style="text-align: right;">
                            {int(cas_pred_max)} cas
                        </td></tr>
                    </table>
                </div>
            </div>
            """
            
            fill_color = colormap_pred(variation_pct) if pd.notna(variation_pct) else '#e0e0e0'
            
            folium.GeoJson(
                row['geometry'],
                style_function=lambda x, color=fill_color: {
                    'fillColor': color,
                    'color': 'black',
                    'weight': 0.5,
                    'fillOpacity': 0.7
                },
                tooltip=folium.Tooltip(
                    f"<b>{aire_name}</b><br>Variation : {variation_pct:+.1f}%",
                    sticky=True
                ),
                popup=folium.Popup(popup_html, max_width=400)
            ).add_to(m_pred)
        
        st_folium(m_pred, width=1400, height=650)
        
        st.header("ğŸ’¾ Export des RÃ©sultats")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            csv_pred = risk_df.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="ğŸ“¥ SynthÃ¨se prÃ©dictions (CSV)",
                data=csv_pred,
                file_name=f"predictions_synthese_{pays_selectionne if pays_selectionne else 'pays'}_{datetime.now().strftime('%Y%m%d')}.csv",
                mime="text/csv"
            )
        
        with col2:
            csv_detail = future_df.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="ğŸ“… DÃ©tail par semaine (CSV)",
                data=csv_detail,
                file_name=f"predictions_detail_{pays_selectionne if pays_selectionne else 'pays'}_{datetime.now().strftime('%Y%m%d')}.csv",
                mime="text/csv"
            )
        
        with col3:
            geojson_str = sa_gdf_pred.to_json()
            st.download_button(
                label="ğŸ—ºï¸ Carte prÃ©dictions (GeoJSON)",
                data=geojson_str,
                file_name=f"carte_predictions_{pays_selectionne if pays_selectionne else 'pays'}_{datetime.now().strftime('%Y%m%d')}.geojson",
                mime="application/json"
            )
        
        output = BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            risk_df.to_excel(writer, sheet_name='Synthese', index=False)
            future_df.to_excel(writer, sheet_name='Detail_Semaines', index=False)
            cases_by_area.to_excel(writer, sheet_name='Cas_Observes', index=False)
            age_stats.to_excel(writer, sheet_name='Analyse_Age', index=False)
            weekly_cases.to_excel(writer, sheet_name='Historique_Hebdo', index=False)
        
        st.download_button(
            label="ğŸ“Š Rapport complet (Excel)",
            data=output.getvalue(),
            file_name=f"rapport_complet_{pays_selectionne if pays_selectionne else 'pays'}_{datetime.now().strftime('%Y%m%d')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True
        )
        
        st.header("ğŸ’¡ Recommandations OpÃ©rationnelles")
        
        aires_critiques_hausse = risk_df[risk_df["Variation_Pct"] >= seuil_hausse]["Aire_Sante"].tolist()
        aires_amelioration = risk_df[risk_df["Variation_Pct"] <= -seuil_baisse]["Aire_Sante"].tolist()
        
        if aires_critiques_hausse:
            st.error(f"ğŸš¨ **{len(aires_critiques_hausse)} aire(s) Ã  risque CRITIQUE (hausse â‰¥{seuil_hausse}%)**")
            
            for i, aire in enumerate(aires_critiques_hausse[:5], 1):
                aire_info = risk_df[risk_df["Aire_Sante"] == aire].iloc[0]
                st.write(f"{i}. **{aire}** : {aire_info['Variation_Pct']:+.1f}% - Pic S{aire_info['Semaine_Pic']} ({int(aire_info['Cas_Predits_Max'])} cas)")
            
            if len(aires_critiques_hausse) > 5:
                st.caption(f"... et {len(aires_critiques_hausse)-5} autre(s)")
            
            st.write("")
            st.write("**Actions prioritaires recommandÃ©es :**")
            st.write("âœ… Renforcer la surveillance Ã©pidÃ©miologique hebdomadaire dans ces aires")
            st.write("âœ… Organiser des campagnes de vaccination de rattrapage urgentes")
            st.write("âœ… PrÃ©positionner les stocks de vaccins et intrants mÃ©dicaux")
            st.write("âœ… Sensibiliser les communautÃ©s aux signes d'alerte de la rougeole")
            st.write("âœ… Coordonner avec les partenaires (OMS, UNICEF, MSF)")
            st.write("âœ… PrÃ©parer les structures de santÃ© Ã  une augmentation de cas")
        
        if aires_amelioration:
            st.success(f"âœ“ **{len(aires_amelioration)} aire(s) montrent une amÃ©lioration (baisse â‰¥{seuil_baisse}%)**")
            st.write("**Bonnes pratiques Ã  capitaliser :**")
            st.write("â€¢ Documenter les interventions ayant conduit Ã  cette baisse")
            st.write("â€¢ Partager les leÃ§ons apprises avec les autres aires")
            st.write("â€¢ Maintenir la vigilance pour Ã©viter une rÃ©surgence")
        
        if not aires_critiques_hausse and not aires_amelioration:
            st.info("â„¹ï¸ **Situation stable** - Aucune variation significative dÃ©tectÃ©e")
            st.write("â€¢ Maintenir la surveillance de routine")
            st.write("â€¢ Continuer les activitÃ©s de vaccination selon le calendrier")
        
        st.markdown("---")
        st.caption(f"""
**MÃ©thodologie de prÃ©diction :**
ModÃ¨le : {modele_choisi} | Score RÂ² (validation croisÃ©e) : {cv_mean:.3f} (Â±{cv_std:.3f}) |
Variables : {len(feature_cols)} features (historique 4 semaines, dÃ©mographie, urbanisation, climat, vaccination) |
PÃ©riode : S{derniere_semaine_epi+1} Ã  S{min(derniere_semaine_epi+n_weeks_pred, 52)} ({n_weeks_pred} semaines) |
Seuils : Baisse â‰¥{seuil_baisse}%, Hausse â‰¥{seuil_hausse}%, Alerte â‰¥{seuil_alerte_epidemique} cas/sem
        """)

else:
    st.info("ğŸ‘† Cliquez sur le bouton ci-dessus pour lancer la modÃ©lisation prÃ©dictive")
    st.markdown("""

    """)

st.markdown("---")
st.caption(f"""
Dashboard de Surveillance Rougeole - Version 3.0 (AmÃ©liorÃ©e) |
GÃ©nÃ©rÃ© le {datetime.now().strftime('%d/%m/%Y Ã  %H:%M')} |
Pays : {pays_selectionne if pays_selectionne else 'Non spÃ©cifiÃ©'} |
PÃ©riode : {start_date} - {end_date} |
Nombre d'aires : {len(sa_gdf)} |
Cas analysÃ©s : {len(df):,} |
Mode : {mode_demo}
""")
